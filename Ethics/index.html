<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<!-- Header !-->
	<head>
		<title>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<!--[if lte IE 8]><script src="../assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="../assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="../assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="../assets/css/ie8.css" /><![endif]-->
        <style>
        .image_off, #home:hover .image_on{
           display:none
        }
        .image_on, #home:hover .image_off{
           display:block
        }
        </style>
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="../index.html" class="logo"><strong>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</strong></a>
								</header>
<!-- End Header !-->

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Ethics Class Discussion Questions</h1>
									</header>

									<p>
										We will have 5 ethics discussions throughout the semester.  Students will read various articles and watch videos related to different topics.  Below are the reading/watching assignments and associated discussion questions.
									</p>

									<HR>
										<h2><a name = "intro">Ethics Discussion #1: Bias, Social Media, Current vs Future Harms</a></h2>

										<p>
											We will try to go over a few different topics as a general introduction to AI and ethics.  Read the links below and answer the 6 questions on canvas.  I will have more questions for us to discuss as a group in class.
										</p>

											<ol>
												<li>
													<h4>AI Bias</h4>
													Read <a href = "https://www.wired.com/story/wrongful-arrests-ai-derailed-3-mens-lives/">this article</a> about wrongful arrests due to facial recognition, as well as this <a href = "https://www.theverge.com/c/22444020/chicago-pd-predictive-policing-heat-list">horrific article</a> about how predictive policing got an innocent man shot twice.  Finally, read <a href = "https://www.theverge.com/21298762/face-depixelizer-ai-machine-learning-tool-pulse-stylegan-obama-bias">this article</a> about a generative AI SNAFU back in 2020, and watch this <a href = "https://www.youtube.com/watch?v=lupwPoSwAec">one minute video by Latanya Sweeney</a> (<a href = "https://time.com/4475627/is-technology-capable-of-being-racist/">Click here</a> to see an opposing point of view by John McWhorter).
													<ul>
														<li>
															<b>Q 1.1</b> How do people in these articles posit it is possible for algorithms to be "biased"? (Come to class ready to expand on this as well)
														</li>
														<li>
															<b>Q 1.2</b> According to these articles, why might victims of AI misclassification not seek redress?
														</li>
													</ul>
												</li>
												<li>
													<h4>AI in Social Media</h4>
													Read <a href = "https://www.theguardian.com/technology/2021/feb/04/facebook-groups-misinformation">this article</a> on how Facebook groups led to the proliferation of white supremacist content.  Then, skim <a href = "https://www.cnbc.com/2023/05/26/tech-companies-are-laying-off-their-ethics-and-safety-teams-.html">this article</a> about layoffs of trust/safety teams at large tech companies (also optionally read <a href = "https://www.technologyreview.com/2021/07/29/1030260/facebook-whistleblower-sophie-zhang-global-political-manipulation/">this article</a> about Facebook whistleblower Sophie Zhang, and note that at Twitter <a href = "https://blog.twitter.com/engineering/en_us/topics/insights/2021/algorithmic-bias-bounty-challenge">this challenge</a> was shutdown after leadership changed).  Finally, skim <a href = "https://www.wired.com/story/tiktok-platforms-cory-doctorow/">this article</a> about the "enshitification" of social platforms as they scale.
													<ul>
														<li>
															<b>Q 2.1</b>: Where is AI/automation used in social media platforms?
														</li>
														<li>
															<b>Q 2.2</b>: What are the perverse incentives social media platforms face when choosing to automate recommendations, and when choosing to automate content moderation?
														</li>
													</ul>
												</li>
												<li>
													<h4>Current vs Future Harms of AI/Automation</h4>
													Browse through some hypothetical future misues of AI at <a href = "https://www.safe.ai/ai-risk">this link</a>.  Then, read a rebuttal article at <a href = "https://www.scientificamerican.com/article/we-need-to-focus-on-ais-real-harms-not-imaginary-existential-risks/">this link</a> by Bender/Hanna.
													<ul>
														<li>
															<b>Q 3.1</b>: Give three examples of current harms of AI that Bender/Hanna mentioned.  Give three examples of hypothetical future harms of AI that safe.ai mentions.
														</li>
														<li>
															<b>Q 3.2</b>: What would Bender/Hanna say about the claim that we need to be concerned about AI surpassing human intelligence?
														</li>
													</ul>
												</li>
											</ol>

									<HR>
										<h2><a name = "corporatecapture">Ethics Discussion #2: Corporate Capture And Colonial Practices</a></h2>

										<ol>
											<li>

												<h4>Corporate Capture</h4>
												<p>
													Read <a href = "https://filosofias.es/wiki/lib/exe/fetch.php/podcast/episodios/ssrn-id4135581.pdf">"The Steep Cost of Capture"</a> by <a href = "https://ainowinstitute.org/author/meredith-whittaker">Meredith Whittaker</a>, then answer the following questions:
												</p>
												<ul>
													<li>
														<b>Q 1.1</b> According to Whittaker, what led to the inception of the current "AI summer," starting in 2012?  What role do corporations play in this?
													</li>
													<li>
														<b>Q 1.2</b> How does the nature of the current AI summer impact academic researchers?  What are some ways that academic researchers cope with this?
													</li>
													<li>
														<b>Q 1.3</b> What ulterior motives does Whittaker posit Eric Schmidt has when shaping the NDAA?
													</li>
												</ul>
											</li>

											<li>
												<h4>Colonial Practices</h4>
												<p>
													Read <a href = "https://time.com/6247678/openai-chatgpt-kenya-workers/">this Time magazine article</a> from last January (warning: it is disturbing).  
												</p>
												<ul>
													<li><b>Q 2.1</b> What were the Kenyan workers contributing to the tech behind ChatGPT?  How much did they make?</li>
													<li>
														<b>Q 2.2</b> What were the "occupational hazards" of the data labeling work the Sama contractors did for OpenAI?  How did Sama allegedly address this?
													</li>
													<li>
														<b>Q 2.3</b> How much was OpenAI worth at the time the article was written?  How much did they pay for the total contract with Sama to curate a dataset of illegal images? 
													</li>
												</ul>

												<p>
													Other related articles (optional): 
													<ul>
														<li>
															<a href = "https://www.theguardian.com/technology/2023/aug/02/ai-chatbot-training-human-toll-content-moderator-meta-openai">The Guardian: Lives and families torn apart by OpenAI</a>
														</li>
														<li>
															<a href = "https://www.nbcnews.com/tech/innovation/openai-chatgpt-ai-jobs-contractors-talk-shadow-workforce-powers-rcna81892">NBC News: American AI data labelers</a>
														</li>
														<li>
															<a href = "https://time.com/6297403/the-workers-behind-ai-rarely-see-its-rewards-this-indian-startup-wants-to-fix-that/">Time: Karya, An Ethically Alternative Data Labeling Company in India?</a>
														</li>
														<li>
															<a href = "https://www.technologyreview.com/supertopic/ai-colonialism-supertopic/">Technology Review: Supertopic on AI Colonialism</a>
														</li>
													</ul>
												</p>

											</li>
										</ol>

										<HR>
											<h2><a name = "music">Ethics Discussion #3 AI And Art / Music</a></h2>
											<p>
												The topic of AI art is vast and rapidly evolving in the "age of generative AI."  We will focus our readings primarily on image generation, as this is what students will implement in HW6, and I want students to be aware of what can happen when large swaths of unexamined data are fed to train these models.  To that end, read the <a href = "https://www.bloomberg.com/graphics/2023-generative-ai-bias/">following Bloomberg article</a> and answer the questions that follow:
												<ol>
													<li>
														Give 3 examples of how bias from this dataset shows up in generative images
													</li>
													<li>
														Post an answer to the following <b>on our discord class channel:</b> A developer for <a href = "https://stablediffusionweb.com/">stable diffusion</a> says the following:
														<p>
	
	"By open-sourcing our models, we aim to support the AI community and collaborate to improve bias evaluation techniques and develop solutions beyond basic prompt modification"
														</p>
	<p>
		Given what you know after reading the Bloomberg article and how models are trained, to what extent do you agree with this statement?  Why?
	</p>
													</li>
													<li>
														Post a response to the following <b>on our discord class channel</b>: 
	The <a href = "https://laion.ai/blog/laion-5b/">Laion3 dataset</a> is an index of images and associated metadata that was used to train Stable Diffusion (among other models).  The creators of this dataset say the following:
	<p>
		"do not recommend using it for creating ready-to-go industrial products, as the basic research about general properties and safety of such large-scale models, which we would like to encourage with this release, is still in progress"
	</p>
	
	<p>
		Prove that this disclaimer is not being heeded.  Beyond this disclaimer, are there other ethical responsibilities you think those who curate such links have?
	</p>
													</li>
	
													<li>
														Read the <a href = "https://www.alamy.com/blog/ai-and-your-images-protecting-rights-and-creating-opportunities">mission statement</a> from the company Alamy about protecting the rights of people who created art used in training.  What happened with Getty images and generative AI?  What is Alamy doing to address a similar issue?
													</li>
												</ol>
												
											</p>
	
											<p>
												Though the readings focus on images, in class, we will focus on the music side in generative AI.  To that end, we will have a live discussion with <a href = "https://www.encantimusic.com/">Ben Cantil</a>, a <a href = "https://soundcloud.com/zebblerencantiexperience">musician</a> and visiting assistant professor of music production, technology, and innovation at <a href = "https://valencia.berklee.edu/">Berklee School of Music, Valencia</a>, who is currently product lead at a startup called <a href = "https://datamindaudio.ai/">DataMindAudio</a> that is making an ethical approach to sourcing music data central to its mission.
											</p>
	
	
											<h4>Other Links</h4>
											<li>
												<a href = "https://www.theguardian.com/artanddesign/2023/may/15/design-me-a-chair-made-from-petals-the-artists-pushing-the-boundaries-of-ai">The Guardian: "Design me a chair made from petals!"": The artists pushing the boundaries of AI</a> (sadly the link to the original conference they were covering seems to be down, but there are a lot of good examples in the article still)
												
											</li>
											<li>
												Carlini, Nicolas, et al. Extracting training data from diffusion models."<a href = "https://www.usenix.org/system/files/usenixsecurity23-carlini.pdf"></a>" 32nd USENIX Security Symposium (USENIX Security 23). 2023
												<p>
													This paper shows how diffusion models are more prone to memorizing their training data than other generative image models like generative adversarial nets.
												</p>
											</li>
											<li>
												For a related issue in the text world, see the following <a href = "https://www.wsj.com/articles/chatgpt-ai-artificial-intelligence-openai-personal-writing-5328339a">WSJ: "Chatbots Are Digesting the Internet. The Internet Wants to Get Paid."</a>
											</li>
											<li>
												<a href = "https://www.theguardian.com/music/2023/apr/18/oasis-aisis-band-fronted-by-an-ai-liam-gallagher">The Guardian: "We got bored waiting for Oasis to re-form: AIsis, the band fronted by an AI Liam Gallagher"</a>
											</li>


									<HR>
										<h2><a name = "climate">Ethics Discussion #4: AI And The Climate Crisis</a></h2>
										<p>
											AI is often touted as a potential solution to the climate crisis we're facing, but the environmental costs of AI are less often discussed.  This part of the ethics unit will focus on two papers: 
										</p>

										<Ul>
											<li>Strubell, E., Ganesh, A., & McCallum, A. (2020). Energy and Policy Considerations for Modern Deep Learning Research. Proceedings of the AAAI Conference on Artificial Intelligence, 34(09), 13693-13696. <a href = "https://doi.org/10.1609/aaai.v34i09.7123">https://doi.org/10.1609/aaai.v34i09.7123</a></li>
											<li>
												Luccioni, Alexandra Sasha, Sylvain Viguier, and Anne-Laure Ligozat. "Estimating the carbon footprint of bloom, a 176b parameter language model." Journal of Machine Learning Research, 23-0069 (2022). <a href = "https://www.jmlr.org/papers/volume24/23-0069/23-0069.pdf">https://www.jmlr.org/papers/volume24/23-0069/23-0069.pdf</a>

												
											</li>
										</Ul>

										<p>
											We will not be discussing this as a class; rather, students will examine some of these topics on their own and explore further in HW7 on diffusion models, where they will use <a href = "https://codecarbon.io/">code carbon</a> to get a carbon footprint of their code.
										</p>

										<h4>
											Strubell 2020
										</h4>
										<p>
											Read section and beginning of 2, skim 2.1 and 3, and reach 4 and 5 of the <a href = "https://doi.org/10.1609/aaai.v34i09.7123">Strubell Paper</a>.  As they explain, the carbon cost of training a single model is estimated to be quite high (e.g. equivalent to ~1 roundtrip NYC to SF trip for 1 person to train <a href = "https://huggingface.co/bert-base-uncased">BERT<SUB>base</SUB></a> for 3 days).  Even so, one might argue that this is a one-time cost and so it shouldn't concern us.  However, as the authors hint at in table 4, one often has to explore and train many models during research and development, or during some meta-search phase, to find the best one that is ultimately described, released or used in production.  When we consider that tens of thousands of groups are doing this continuously across industry, academia, and government agencies, these costs add up.  And this is only part of the story; models require continuous energy to evaluate queries in production, and we also have to consider the lifecycle of the hardware that's involved.  In fact, <a href = "https://blog.research.google/2022/02/good-news-about-carbon-footprint-of.html">Google admitted</a> back in 2022 that machine learning accounts for roughly 15% of Google's total energy use, and Google is a behemoth company!  So hopefully it is clear why this is an important problem to consider.
										</p>

										<p>
											Given the above context, and after reading the paper, answer the following questions:
										</p>
										<ul>
											<li>
												<b>Q 1.1</b> What are the 3 components of energy that the authors measured?  How did they measure them?
											</li>
											<li>
												<b>Q 1.2</b> What are examples of algorithms that the authors point to that can help reduce environmental impact during training?
											</li>
											<li>
												<b>Q 1.3</b> <a href = "https://towardsdatascience.com/the-evolved-transformer-enhancing-transformer-with-neural-architecture-search-f0073a915aca">Neural architecture search (NAS) for the "evolved transformer model"</a> is an example of searching through many models to find the best one.  <a href = "https://blog.research.google/2022/02/good-news-about-carbon-footprint-of.html">Google claims</a> that the Strubell paper overestimated the training cost of NAS.  <a href = "https://blog.research.google/2022/02/good-news-about-carbon-footprint-of.html">Click here</a> to read the press release from a Google research paper.  <b>If we are to take Google at their word</b>, how many round trip flights (avg for a single passenger) is training NAS actually equivalent to?
											</li>
										</ul>

										<h4>Luccioni 2022</h4>
										<p>
											<a href = "https://huggingface.co/bigscience/bloom">BigScience Large Open-science Open-access Multilingual Language Model (BLOOM)</a>, which has 176B parameters, is a model in comparable performance to GPT-3 (the direct precursor to GPT 3.5, otherwise known as ChatGPT), and in comparable size to GPT3 and GPT3.5.  The authors of <a href = "https://www.jmlr.org/papers/volume24/23-0069/23-0069.pdf">this Journal of Machine Learning Research paper</a> by Luccioni, Viguier, and Ligozat, estimate the cost of training this model, and their work serves as a slightly more recent pulse on the carbon costs of large language models than the Strubell paper.
										</p>


										<ul>
											<li>
												<b>Q 2.1</b> Look at section 4.2 of <a href = "https://www.jmlr.org/papers/volume24/23-0069/23-0069.pdf">their paper</a>.  Noting that a ton is 2000 pounds, how many equivalent round trip NYC->SF flights (for a single person) did the authors estimate was the cost of the dynamic power consumption when training BLOOM?
											</li>
										</ul>

										<h4>NeurIPS Workshop on Tackling Climate Change with Machine Learning</h4>
										<p>
											<a href = "https://nips.cc/">NeurIPS</a>, the flagship conference on machine learning, has been holding an annual workshop on tackling climate change with machine learning since 2019.  <a href = "https://www.climatechange.ai/events/neurips2022">Click here</a> to view the accepted papers and posters from last December.
										</p>
										<ul>
											<li>
												<b>Q 3.1</b>: Skim the proceedings and find a paper or poster that interests you.  Have a look through the paper, and summarize briefly to the class <b>in a thread on discord</b> what that paper is doing and why it interests you.
											</li>
										</ul>

										<p>
											Keep your eyes on the <a href = "https://www.climatechange.ai/events/neurips2023">2023 workshop</a>, which is right around the corner in a few weeks!
										</p>


										<h4>Other resources</h4>
										<ul>
											<li>
												See this <a href = "https://dl.acm.org/doi/pdf/10.1145/3485128">2022 survey article on tackling climate change with machine learning</a>.  It's a doozie but a great read, and it paints a picture of just how many industries are involved in the climate crisis, and where machine learning fits into all of them.
											</li>
											<li>
												See this <a href = "https://penntoday.upenn.edu/news/hidden-costs-ai-impending-energy-and-resource-strain">Q&A with Benjamin Lee from Penn</a> (who was actually my computer architecture professor back at Duke in 2011)
											</li>
											<li>
												See this <a href = "https://peertube.dair-institute.org/w/qpKuiNLTuHHMnvWGjnA2D8">recent podcast on the carbon cost of machine learning</a>, which features both Strubell and Luccioni. 
											</li>
										</ul>



						</div>
					</div>

<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
                                        <li>
											<span class="opener">General</span>
											<ul>
												<li><a href = "../index.html#overview">Overview</a></li>
												<li><a href = "../index.html#logistics">Technology Logistics</a></li>
												<li><a href = "../index.html#deliverables">Deliverables</a></li>
												<li><a href = "../index.html#debugging">Debugging Principles</a></li>
												<li><a href = "../index.html#schedule">Schedule</a></li>
												<li><a href = "../index.html#grading">Grading / Deadlines Policy</a></li>
												<li><a href = "../index.html#environment">Classroom Environment</a></li>
												<li><a href = "../index.html#collaboration">Collaboration Policy</a></li>
												<li><a href = "../index.html#other">Other Resources / Policies</a></li>
											</ul> 
										</li>
										<li><a href = "../Software/index.html">Software</a></li>
										<li><a href = "../index.html#schedule">Schedule</a></li>
                                        <li>
											<span class="opener">Assignments</span>
											<ul>
												<li>
													<a href = "../../Modules/Module1/Video1">HW0: Python Self Study Module</a>
												</li>
												<li>
													<a href = "../Assignments/HW1_WelcomeToCS477">HW1: Welcome To CS 477</a>
												</li>
												
												<li>
													<a href = "../Assignments/HW2_RushHour">HW2: The Rush Hour Problem</a>
												</li>
												<li>
													<a href = "../Assignments/HW3_Markov">HW3: Markov Chains for Text Processing</a>
												</li>
												<li>
													<a href = "../Assignments/HW4_FundamentalFreq">HW4: Fundamental Frequency Tracking And Pitch-Based Audio Effects</a>
													<ul>
														<li>
															<a href = "../Assignments/HW4_FundamentalFreq/statements.html">Musical statements</a>
														</li>
													</ul>
												</li>
												<li>
													<a href = "../Assignments/HW5_LogisticRegression">HW5: Logistic Regression on Movie Reviews</a>
												</li>
												<li>
													<a href = "../Assignments/HW6_BYOMLP">HW6: Build Your Own Multilayer Perceptron (BYOMLP)</a>
												</li>
												<!--
												<li>
													<a href = "../Assignments/HW7_DeepLearning">HW7: (Deep) Neural Networks on Images</a>
												</li>
												!-->
											</ul>
										</li>
                                        <li>
											<span class="opener">Class Exercises / Notes</span>
											<ul>
												<li>
													<a href = "../ClassExercises/Week1_Bandit/index.html">Week 1: Introduction To Reinforcement Learning</a>
													<ul>
														<li>
															<a href = "../ClassExercises/Week1_Bandit/jsbandit/index.html">The Multi-Armed Bandit Game</a>
														</li>
													</ul>
												</li>
												<li>
													<a href = "../ClassExercises/Week1_Adventure">Week 1: Choose Your Own Adventure</a>
													<ul>
														<li><a href = "../ClassExercises/Week1_Adventure/index.html#student">Student Adventures</a></li>
													</ul>
												</li>
												<li>
													<a href = "../Materials/MazeExplorer">Week 2: Maze Searching Game</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week2_BasicSearch">Week 2: Blind Maze Searching</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week2_8Puzzle">Week 2: 8 Puzzle</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week3_PrioritySearch">Week 3: Uniform Cost, Greedy Best-First, and A* Search</a>
												</li>
												<li>
													<a href = "https://ursinus.instructure.com/courses/16260/assignments/186957">Week 3: An Admissible But Not Consistent Heuristic</a>
												</li>
												<li>
													<a href = "../../Modules/Module2/Video1">Week 4: Probability Module</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week4_Markov">Week 4: Markov Chains of Characters</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week4_MarkovText">Week 4: Markov Chains for Document Representations</a>
												</li>
												<li>
													<a href = "https://ursinus.instructure.com/courses/16260/quizzes/24127">Week 4: Bayes Rule Module</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week5_NaiveBayes">Week 5: Bayes Rule And Naive Bayes Classifiers</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week5_BagOfWords">Week 5: Bag of Words Naive Bayes Exercise</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week6_HMM">Week 5/6: Hidden Markov Models / Bayes Filtering / Viterbi Notes</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week5_RobotLocalization">Week 5/6: Robot Localization</a>
												</li>
												<li>
													<a href = "https://ursinus-cs477-f2023.github.io/Modules/HMM/Video1">Week 6: HMM Module</a>
												</li>
												<li>
													<a href = "https://github.com/ursinus-cs477-f2023/Week6_MDP">Week 6: Markov Decision Processes And Pong AI</a>
												</li>
												<li>
													<a href = "../../Modules/VectorModule/Video1">Week 7: Euclidean Vectors / Data Vectorization Module</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week7_DigitsNN/index.html">Week 7: K-Nearest Neighbors And Digits Classification</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week5_KMeans">Week 7: KMeans Clustering And Visual Bag of Words</a>
												</li>
												<li>
													<a href = "../../Modules/MatrixModule/Video1">Week 7: Matrix Module</a>
												</li>
												<li>
													<a href = "ClassExercises/Week7_PCA/Week7_PCA/UnsupervisedDigits.html">Week 7: PCA on MNIST Digits</a>
												</li>
												<li>
													<a href = "../ClassExercises/Week10_LogisticRegression/index.html">Week 8: Logistic Regression And Gradient Descent</a>
												</li>
												<li>
													<a href = "../../Modules/LogisticRegression/Video1">Week 8: Neural Networks Module 1</a>
												</li>
												<li>
													<a href = "../../Modules/Softmax/Video1">Week 9: Softmax Module</a>
												</li>
												<li><a href = "../../Modules/NeuralNets/Video0">Week 9/10: Multi-Class Logistic Regression And Feedforward Neural Nets Module</a></li>
												<li>
													<a href = "../ClassExercises/Week10_Backprop/index.html">Week 10: Backpropagation on Multilayer Perceptrons</a>
												</li>
												<li>
													<a href = "../../Modules/Backprop/Video1">Week 10: Backpropagation Module</a>
												</li>
												<li>
													<a href = "https://github.com/ursinus-cs477-f2023/CoursePage/blob/main/ClassExercises/Week11_CNNs/CatDog_Train_Better.ipynb">Week 11: Convolutional Neural Network with Data Augmentation for Cats vs Dogs</a>
												</li>
												<li>
													<a href = "../../Modules/VAEGAN/Video1">Week 13/14: Variational Autoencoder / GAN Module</a>
												</li>
												
												
											</ul>
										</li>
										<li>
											<span class="opener">Ethics Reading / Discussions</span>
											<ul>
												<li><a href = "../Ethics/index.html#intro">Bias, Social Media, Current vs Future Harms</a></li>
												<li><a href = "../Ethics/index.html#corporatecapture">Corporate Capture And Colonial Practices</a></li>
												<li><a href = "../Ethics/index.html#music">The Ethics of AI in Art / Music</a></li>
												<li><a href = "../Ethics/index.html#climate">AI And The Climate Crisis</a></li>
												<li><a href = "../FinalProject/index.html">Final Ethics Project</a></li>
											</ul>
										</li>
										
									</ul>
								</nav>


							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; <a href = "http://www.ctralie.com">Christopher J. Tralie</a>. All rights reserved.  Contact chris.tralie@gmail.com. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

			</div>
			
            <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
            <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- End Sidebar !-->

<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/skel.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="../assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="../assets/js/main.js"></script>
<!-- End Scripts -->
	</body>
</html>
