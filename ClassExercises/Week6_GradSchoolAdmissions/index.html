<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<!-- Header !-->
	<head>
		<title>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<!--[if lte IE 8]><script src="../../assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="../../assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="../../assets/css/ie8.css" /><![endif]-->
        <style>
        .image_off, #home:hover .image_on{
           display:none
        }
        .image_on, #home:hover .image_off{
           display:block
        }
        </style>
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="../../index.html" class="logo"><strong>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</strong></a>
								</header>
<!-- End Header !-->

							<!-- Content -->
								<section>
									<header class="main">
                                        <h2>Week 6: Grad School Admissions And Gaussian Naive Bayes</h2>
                                        <h3><a href = "http://www.ctralie.com">Chris Tralie</a></h3>
									</header>

									<div id="page-content">
                                        <p>
											The purpose of this exercise is to get you familiar with real-valued features and Gaussian Naive Bayes for modeling them.  We'll use a <a href = "https://www.kaggle.com/mohansacharya/graduate-admissions/version/2">graduate school admissions dataset from Kaggle</a> as an example.  Below is some code to load in this data
										</p>

										<script type="syntaxhighlighter" class="brush: python"><![CDATA[
											import pandas as pd
											import numpy as np
											# Load in data
											data = pd.read_csv("Admission_Predict.csv")
											XAll = data[["GRE Score", "TOEFL Score", "University Rating", "SOP", "LOR ", "CGPA"]]
											XAll = XAll.to_numpy()
											y = data["Chance of Admit "].to_numpy().flatten()

											# Split the data roughly in half based on admission chance
											thresh = 0.728
											admit = XAll[y > thresh, :]
											notadmit = XAll[y <= thresh, :]
										</script>  

										<p>
											The data is in a 2D numpy arrays <code>admit</code> and <code>notadmit</code>, where each row holds a different student and each column holds a feature for that student (GRE Score, TOEFL score, Univeristy Rating, Statement of Purpose, Letter of Recommendation, Cumulative GPA).
										</p>

										<p>
											Your job will be to do a <b>leave one out classification</b>; that is, loop through and pull out each of the examples in <code>admit</code> and <code>notadmit</code>, train Naive bayes classifiers on the remaining data for both the admit class and the nonadmit class, and see which model has a higher likelihood for the student you pulled out.  Count how often you are correct based on the group you pulled out the student from.
										</p>

										<h3>Ethics Question</h3>
										<p>
											As you're doing this exercise, reflect on where this type of classification problem could come up, and what the ethical issues of automating it could be.
										</p>

										<h3>Gaussian Naive Bayes</h3>
										<p>
											Recall that for real-valued data, we can't use the same technique as we did for <a href = "../Week5_BagOfWords/">bag of words</a>.  Instead, we switch to a <i>continuous</i> distribution: the Gaussian
										</p>

										<h3>
											\[ p(x) = \frac{1}{\sqrt{2 \pi} \sigma} e^{-(x-\mu)^2 / (2 \sigma^2)} \]
										</h3>

										<p>
											There are two parameters here: the mean &lambda; and the standard deviation &sigma;.  Let's plot a few distributions fixing &mu; at 0 and varying &sigma;
										</p>

										<img src = "GaussExamples.svg" width=400>

										<p>
											As you can see, a larger standard deviation means that the distribution is wider.
										</p>

										<p>
											Interestingly, the Gaussian is a realistic model for a lot of real data because of the <a href = "https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem</a>.  If we simply make &mu; be the sample mean 
										</p>

										<h3>
											\[ \overline{X} = \frac{1}{N}\sum_{i = 1}^N x_i \]
										</h3>

										<p>
											and the standard deviation be the sample standard deviation
										</p>

										<h3>
											\[ \overline{\sigma} = \sqrt{\frac{1}{N}\sum_{i = 1}^N (x_i - \overline{X})^2} \]
										</h3>

										<p>
											Then we get a pretty good fit on the data above.  The pictures below show the histogram of not admitted (blue) versus admitted (orange), and the fit of the Gaussians superimposed over them.  What we see is while there is overlap between both distributions, the Gaussians are shifted to the left in the non admit distribution for every variable, which reflects the notion we have that doing better at any of these variables increases chances of being admitted.
										</p>

										<p>
											<img src = "Histograms.svg" width = 800>
										</p>

										<p>
											In the Naive Bayes framework, if you treat every variable as being independent (which they certainly are not in the above data!), then we simply multiply together a bunch of Gaussians
										</p>

										<h3>
											\[ p(x | C) = \frac{1}{\sqrt{2 \pi} \sigma_{C1}} e^{-(x_1-\mu_{C1})^2 / (2 \sigma_{C1}^2)} \times \frac{1}{\sqrt{2 \pi} \sigma_{C2}} e^{-(x_2-\mu_{C2})^2 / (2 \sigma_{C2}^2)} \times ... \]
										</h3>

										<p>
											where <b>(&mu;<SUB>Ck</SUB>, &sigma;<SUB>Ck</SUB>)</b> are the mean and standard deviation, respectively, of variable <b>k</b> under model <b>C</b>. If we take the log of this, we get a pretty nice expression
										</p>

										<h3>
											\[ \log p(x | C) = \log \frac{1}{\sqrt{2 \pi} \sigma_{C1}} -(x_1-\mu_{C1})^2 / (2 \sigma_{C1}^2) + \log \frac{1}{\sqrt{2 \pi} \sigma_{C2}}  - (x_2-\mu_{C2})^2 / (2 \sigma_{C2}^2) + ...\]
										</h3>

										<p>
											Here, we can see clearly that the further a variable gets away from the mean of the Gaussian, the more negative the log likelihood will become for this model.  So the maximum likelihood point is directly at the mean of each variable.
										</p>

										<h3>Histogram-Based Naive Bayes</h3>
										<p>
											If you finished early and are looking for things to do, you can try the same problem using histograms to represent discrete outcomes instead of fitting Gaussians.
										</p>



											





                                    
                                </div>
						</div>
					</div>

					<!--LaTeX in Javascript!-->
					<script src="../../../../jsMath/easy/load.js"></script>
					<!--Syntax highlighting in Javascript!-->
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shCore.js"></script>
					<script type="text/javascript" src="../../../syntaxhighlighter/scripts/shBrushJScript.js"></script>
                    <script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushCpp.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushXml.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushMatlabSimple.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushPython.js"></script>
					<link type="text/css" rel="stylesheet" href="../../../../syntaxhighlighter/styles/shCoreDefault.css"/>
					<script type="text/javascript">SyntaxHighlighter.all();</script>

<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
                                        <li>
											<span class="opener">General</span>
											<ul>
												<li><a href = "../../index.html#overview">Overview</a></li>
												<li><a href = "../../index.html#logistics">Technology Logistics</a></li>
												<li><a href = "../../index.html#deliverables">Deliverables</a></li>
												<li><a href = "../../index.html#debugging">Debugging Principles</a></li>
												<li><a href = "../../index.html#schedule">Schedule</a></li>
												<li><a href = "../../index.html#grading">Grading / Deadlines Policy</a></li>
												<li><a href = "../../index.html#environment">Classroom Environment</a></li>
												<li><a href = "../../index.html#collaboration">Collaboration Policy</a></li>
												<li><a href = "../../index.html#other">Other Resources / Policies</a></li>
											</ul> 
										</li>
										<li><a href = "../../Software/index.html">Software</a></li>
										<li><a href = "../../index.html#schedule">Schedule</a></li>
                                        <li>
											<span class="opener">Assignments</span>
											<ul>
												<li>
													<a href = "../../../Modules/Module1/Video1">HW0: Python Self Study Module</a>
												</li>
												<li>
													<a href = "../../Assignments/HW1_WelcomeToCS477">HW1: Welcome To CS 477</a>
												</li>
												
												<li>
													<a href = "../../Assignments/HW2_RushHour">HW2: The Rush Hour Problem</a>
												</li>
												<!--
												<li>
													<a href = "../../Assignments/HW3_Markov">HW3: Markov Chains for Text Processing</a>
												</li>
												<li>
													<a href = "../../Assignments/HW4_RobotLocalization">HW4: Bayesian Robot Localization</a>
												</li>
												<li>
													<a href = "../../Assignments/HW5a_3DShapeCluster">HW5a: 3D Shape Clustering</a>
												</li>
												<li>
													<a href = "../../Assignments/HW5b_Unsupervised">HW5b: NMF for Music Component Separation</a>
												</li>
												<li>
													<a href = "../../Assignments/HW6_LogisticRegression">HW6: Logistic Regression on Movie Reviews</a>
												</li>
												<li>
													<a href = "../../Assignments/HW7_DeepLearning">HW7: (Deep) Neural Networks on Images</a>
												</li>
												!-->
											</ul>
										</li>
                                        <li>
											<span class="opener">Class Exercises / Notes</span>
											<ul>
												<li>
													<a href = "../../ClassExercises/Week1_Bandit/index.html">Week 1: Introduction To Reinforcement Learning</a>
													<ul>
														<li>
															<a href = "../../ClassExercises/Week1_Bandit/jsbandit/index.html">The Multi-Armed Bandit Game</a>
														</li>
													</ul>
												</li>

												<li>
													<a href = "../../ClassExercises/Week1_Adventure">Week 1: Choose Your Own Adventure</a>
													<ul>
														<li><a href = "../../ClassExercises/Week1_Adventure/index.html#student">Student Adventures</a></li>
													</ul>
												</li>
												<li>
													<a href = "../../Materials/MazeExplorer">Week 2: Maze Searching Game</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week2_BasicSearch">Week 2: Blind Maze Searching</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week2_8Puzzle">Week 2: 8 Puzzle</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week3_PrioritySearch">Week 3: Uniform Cost, Greedy Best-First, and A* Search</a>
												</li>
												<li>
													<a href = "https://ursinus.instructure.com/courses/16260/assignments/186957">Week 3: An Admissible But Not Consistent Heuristic</a>
												</li>
												<li>
													<a href = "../../../Modules/Module2/Video1">Week 4: Probability Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week4_Markov">Week 4: Markov Chains of Characters</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_BagOfWords">Week 5: Bag of Words Exercise / Theory of Bayesian Classifiers</a>
													<ul>
														<li><a href = "../../ClassExercises/Week5_BagOfWords#exercise">Text Classification Exercise</a></li>
														<li><a href = "../../ClassExercises/Week5_BagOfWords#theory">Naive Bayes Theory</a></li>
													</ul>
												</li>
												<li>
													<a href = "../../../Modules/Module3/Exercise0">Week 5: Bayes Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week6_HMM">Week 6: Hidden Markov Models / Bayes Filtering / Viterbi Notes</a>
												</li>
												<li>
													<a href = "../../../Modules/VectorModule/Video1">Week 7: Euclidean Vectors / Data Vectorization Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week7_DigitsNN.html">Week 7: K-Nearest Neighbors And Digits Classification</a>
												</li>
												<li>
													<a href = "../../../Modules/MatrixModule/Video1">Week 8: Matrix Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week10_LogisticRegression/index.html">Week 10/11: Logistic Regression And Gradient Descent</a>
												</li>
												
											</ul>
										</li>
										<li><a href = "../../Ethics/index.html">Ethics Reading / Discussions</a></li>
										<li><a href = "../../FinalProject/index.html">Final Ethics Project</a></li>
									</ul>
								</nav>


							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; <a href = "http://www.ctralie.com">Christopher J. Tralie</a>. All rights reserved.  Contact chris.tralie@gmail.com. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

			</div>
			
            <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
            <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- End Sidebar !-->

<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/skel.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="../../assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="../../assets/js/main.js"></script>
<!-- End Scripts -->
