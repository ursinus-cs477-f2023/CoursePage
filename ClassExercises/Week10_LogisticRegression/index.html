<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<!-- Header !-->
	<head>
		<title>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<!--[if lte IE 8]><script src="../../assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="../../assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="../../assets/css/ie8.css" /><![endif]-->
        <style>
        .image_off, #home:hover .image_on{
           display:none
        }
        .image_on, #home:hover .image_off{
           display:block
        }
        </style>
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="../../index.html" class="logo"><strong>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</strong></a>
								</header>
<!-- End Header !-->

							<!-- Content -->
								<section>
									<header class="main">
                                        <h2>Week 10/11: Logistic Regression</h2>
                                        <h3><a href = "http://www.ctralie.com">Chris Tralie</a></h3>
									</header>

									<div id="page-content">

										<h2><a name = "step">Step Function Regression for 1D Data And Grid Search</a></h2>
										<p>
											Let's consider the following supervised learning problem.  We have data with a single coordinate and two classes we want to sort it into: blue dots (0) or orange stars (1), as shown below:
										</p>

										<img src = "1DMotivation.svg" width=700>

										<p>
											For our model, let's try to create a function of a single variable <b>x</b> that returns a 0 for some ranges of <b>x</b> where we find the blue dots, and a 1 for other ranges of <b>x</b> where we find the orange dots.  The simplest possible function we could define is a step function
 										</p>

										<div style="width:200px;">
											<h3>
												\[ s_a(x) = \left\{  \begin{array}{cc} 1 & x > a \\ 0 & x \leq a \end{array} \right\} \]
											</h3>
										</div>

										<p>
											In other words, we want to find a single threshold <b>a</b> above which we believe we have an orange star, and below which we've decided we have a blue dot.  We shouldn't expect to get this 100% correct on the above example since they're mixed together a bit, but this is not a bad model since most of the orange stars are to the right of most of the blue dots.
										</p>

										<p>
											To score how well different <b>a</b> values work across all of our data points <b>(x<SUB>i</SUB>, y<SUB>i</SUB>)</b> (where <b>y<SUB>i</SUB></b> is the label, either 0 or 1, that <b>x<SUB>i</SUB></b> has), we can use a <b>squared loss loss function</b> which is the sum of the squared distances between <b>f<SUB>a</SUB>(x<SUB>i</SUB>)</b> and the true values of the dots.  This loss would look like this 
										</p>

										<div style="width:200px;">
											<h3>
												\[ L(a) = \sum_{i = 1}^N (s_a(x_i) - y_i)^2 \]
											</h3>
										</div>

										<p>
											In the case of the step function on the above data, this means we add a penalty of 1 for every point that is misclassified.  If we think back to calc 1, the way that we usually minimize functions is by finding critical points.  Most of the critical points are found by setting the derivative equal to 0 and solving.  The problem with the step function, though, is that it's non-differentiable, so this becomes a pain.  We can instead use something called <b>grid search</b> where we try a whole bunch of values evenly spaced over an interval and see which one leads to a min (an even smarter thing to do in 1D is to use <a href = "https://en.wikipedia.org/wiki/Golden-section_search#Iterative_algorithm">golden section search</a>).  Here's some code that does grid search with 1000 points over the interval [-1, 8] 
										</p>

										<script type="syntaxhighlighter" class="brush: python"><![CDATA[
											a_s = np.linspace(-2, 8, 1000)
											min_loss = np.inf
											min_a = np.inf
											for a in np.linspace(-1, 8, 1000):
												loss_a = np.sum(np.abs(0.5*(1+np.sign(x-a))-y))
												if loss_a < min_loss:
													min_loss = loss_a
													min_a = a
										</script>  



										<p>
											If we do this on the above example and plot the loss function at each <b>a</b> we try, we get this:
										</p>

										<img src = "StepLoss.svg" width=400>

										<p>
											There are a few global mins at a loss of 6, one of which occurs at around <b>a = 2.7</b>.  As shown below, if we plot the value of the step function versus the ground truth value of our data (class 0 or class 1), we can see that 3 orange points got misclassified and 3 blue points got misclassified.
										</p>

										<img src = "StepFit.svg" width=500>
										
										<p>
											This seems like it worked out pretty well!  The problem is that it doesn't scale if we're trying to fit a model that has more than one parameter.  For example, if we have two parameters and we likewise divvy up the range into 1000 evenly spaced regions for each parameter, we have to try a million parameter combinations.  If we have 3 parameters, we have to try a billion.  And in general, if we take <b>N</b> samples of each parameter and we have <b>P</b> parameters, we will have to try <b>N<SUP>P</SUP></b> parameter combinations!  This is known as the <b>curse of dimensionality</b>.  To give you an idea of how bad this is, when we go to classify images, we will have on parameter for pixel.  In a fairly small 100x100 image, this is 10,000 pixels.  If we try even a paltry 10 unique parameter values in grid search, we get <b>10<SUP>10,000</SUP></b> different combinations, which is <b>beyond astronomical</b>.  We're definitely going to need a more sophisticated technique.
										</p>


										<HR>
										<h2><a name = "1Dlogistic">1D Logistic Regression</a></h2>
										<p>
											Let's now try to come up with something that acts like the step function but which is differentiable.  We'll use something called the <b>logistic function</b>, which is defined as 
										</p>

										<div style="width:200px;">
										<h3>
											\[ f(u) = \frac{1}{1+e^{-u}} \]
										</h3>
										</div>

										<p>
											If you plot it, you'll see it's like a step function that makes a smooth transition from 0 to 1
										</p>

										<img src = "Logisticfn.svg" width=500>

										<p>
											This means it acts like the function we were looking for that chooses a boundary between the objects in class 0 and class 1, but it's differentiable.  If we use the chain rule, we can compute its derivative as 
										</p>

										<div style="width:200px;">
											<h3>
												\[ \frac{d f(u)}{du} = \frac{1}{1+e^{-u}} = \frac{e^{-u}}{(1+e^{-u})^2} \]
											</h3>
										</div>

										<p>
											Actually, there's a really slick way to rewrite this as just the following (which you can check with some algebraic manipulations)
										</p>

										<div style="width:200px;">
											<h3>
												\[ \frac{d f(u)}{du} = f(u)(1-f(u)) \]
											</h3>
										</div>

										<p>
											Now let's think about how we might fit the logistic function to our data.  Actually, we'll allow ourselves to have two parameters now: one called <b>a</b> which controls the sharpness of the increase from 0 to 1, and one called <b>b</b> which controls a horizontal shift (at this point you may want to stop and review how <a href = "https://www.geogebra.org/m/yxa2dw5x">to stretch out and horizontally shift functions</a>). In particular, we'll consider how the equation
										</p>

										<div style="width:200px;">
											<h3>
												\[ f(ax + b) =  \frac{1}{1+e^{-ax - b}} \]
											</h3>
										</div>

										<p>
											best fits our data.  Then we can define our <b>squared loss</b> loss function as follows
										</p>

										<div style="width:200px;">
											<h3>
												\[ L(a, b) = \sum_{i=1}^N \left( \frac{1}{1+e^{-ax_i - b}} - y_i \right)^2 \]
											</h3>
										</div>

										<p>
											We want to minimize this function.  As an example of what this looks like, let's fix <b>a = 1</b> and look at grid search again over the horizontal shift parameter <b>b</b>
											
										</p>
										<img src = "LogisticLossGrid.svg">

										<p>
											But let's see what we can do towards optimizing both parameters jointly with a more sophisticated technique. In class, we saw how instead of doing a full on grid search, we could look in a small neighborhood around each point and walk in the direction of where the function seems to be decreasing, and then to repeat this process.  One fundamental optimization technique for doing mathematically is <b>gradient descent</b>, whereby we compute the derivative of our loss with respect to each parameter, treating everything else as a constant.  This is referred to as the <b>partial derivative  &part;</b> with respect to each parameter.  For example, let's consider the partial derivative of our loss with respect to the parameter <b>a</b>.  We can obtain this with multiple applications of the chain rule, noting that everything other than <b>a</b> is a constant
										</p>

										<div style="width:200px;">
											<h3>
												\[ \frac{\partial L(a, b)}{\partial a} = \sum_{i = 1}^N \frac{\partial (f(ax_i+b) - y_i)^2}{\partial a} = \sum_{i=1}^N 2(f(ax_i+b) - y_i) \frac{\partial f(ax_i+b)}{\partial a} \]
											</h3>
											<h3>
												\[ \frac{\partial L(a, b)}{\partial a} = 2(f(ax_i+b) - y_i) f(ax_i+b)(1-f(ax_i+b)) \frac{\partial ax_i+b}{\partial a}\]
											</h3>
											<p>
												and finally
											</p>
											<h3>
												\[  \frac{\partial L(a, b)}{\partial a} = \sum_{i=1}^N 2x_i (f(ax_i+b) - y_i) f(ax_i+b)(1-f(ax_i+b)) \]
											</h3>
										</div>

										<p>
											By a similar procedure, we find that the partial derivative with respect to <b>b</b> is 
										</p>

										<div style="width:200px;">
											<h3>
												\[  \frac{\partial L(a, b)}{\partial b} = \sum_{i=1}^N 2(f(ax_i+b) - y_i) f(ax_i+b)(1-f(ax_i+b)) \]
											</h3>
										</div>

										<p>
											Since the derivative tells us how the function is increasing, we want to walk along the <b>opposite direction</b>.  Therefore, we will update our parameters <b>a</b> and <b>b</b> by <i>subtracting</i> some nonnegative constant <b>&mu;</b> times the derivative.  This parameter <b>&mu;</b> is sometimes referred to as the <b>learning rate</b>
										</p>

										<div style="width:200px;">
											<ul>
												<li>
													\[ a \gets  a - \mu \frac{\partial L(a, b)}{\partial a}\]
												</li>
												<li>
													\[ b \gets  b - \mu \frac{\partial L(a, b)}{\partial b}\]
												</li>
											</ul>
										</div>


										<p>
											Here's what gradient descent looks like after modifying the <a href = "https://github.com/Ursinus-CS477-F2021/Week10_LogisticRegression/blob/main/3-Logistic1DGradient.ipynb">starter code here</a>, with a step <b>&mu; = 0.1</b>
										</p>

										<img src = "Step0.1.gif">

										<p>
											This step size is a bit large and causes it to zig zag.  Here is a smaller step size <b>&mu; = 0.01</b>, which moves more slowly but which does not cause the same zig zagging:
										</p>

										<img src = "Step0.01.gif">

										<p>
											We should be mindful of this tradeoff as we choose our learning rate.  
										</p>


										<HR>
											<h2><a name = "higherdim">Separating Lines in 2D / Higher Dimensional Logistic Regression</a></h2>

											<p>
												We can extend these ideas to higher dimensions.  The very next dimension up leads us to a procedure for separating lines in 2D.  Here, the boundary decision boundary is described with the equation <b>ax + by + c = 0</b>, so there are three parameters: <b>a</b>, <b>b</b>, and <b>c</b>.  Let's now suppose the class labels of our planar data points <b>(x<SUB>i</SUB>, y<SUB>i</SUB>)</b> are called <b>z<SUB>i</SUB></b> to avoid a variable name collision.  This leads us towards minimizing the loss function 
											</p>

											<div style="width:200px;">
												<h3>
													\[ L(a, b, c) = \sum_{i=1}^N \left( \frac{1}{1+e^{-ax_i - by_i - c}} - z_i \right)^2 \]
												</h3>
											</div>

											<p>
												We can work through similar math to find the following update rules for gradient descent
											</p>

											<div style="width:200px;">
												<ul>
													<li>
														\[ a \gets  a - \mu \frac{\partial L(a, b, c)}{\partial a}\]
													</li>
													<li>
														\[ b \gets  b - \mu \frac{\partial L(a, b, c)}{\partial b}\]
													</li>
													<li>
														\[ c \gets  c - \mu \frac{\partial L(a, b, c)}{\partial c}\]
													</li>
												</ul>
											</div>

											<p>
												where
											</p>

											<div style="width:200px;">
												<h3>
													\[  \frac{\partial L(a, b, c)}{\partial a} = \sum_{i=1}^N 2x_i (f(ax_i+by_i+c) - z_i) f(ax_i+by_i+c)(1-f(ax_i+by_i+c)) \]
												</h3>
												<h3>
													\[  \frac{\partial L(a, b, c)}{\partial b} = \sum_{i=1}^N 2y_i (f(ax_i+by_i+c) - z_i) f(ax_i+by_i+c)(1-f(ax_i+by_i+c)) \]
												</h3>
												<h3>
													\[  \frac{\partial L(a, b, c)}{\partial c} = \sum_{i=1}^N 2 (f(ax_i+by_i+c) - z_i) f(ax_i+by_i+c)(1-f(ax_i+by_i+c)) \]
												</h3>
											</div>
											



											<p>
												Here's an example of a working implementation of gradient descent on 2D data starting from <a href = "https://github.com/Ursinus-CS477-F2021/Week10_LogisticRegression/blob/main/4-Logistic2DGradient.ipynb">this file</a>
											</p>

											<img src = "2DExample1.gif">

											<p>
												Here's another example where the line started off in the backwards orientation
											</p>

											<img src = "2DExample2.gif">

											<p>
												Here's an example where the data isn't separable
											</p>
											<img src = "2DExample3.gif">

											<h3>Higher Dimensions</h3>
											<p>
												In general, we can run logistic regression on <b>d</b> independent variables <b>x<SUB>1</SUB></b>, <b>x<SUB>2</SUB></b>, ... <b>x<SUB>d</SUB></b> by fitting with the logistic function composed with 
											</p>
											<div style="width:200px;">
												\[ w_1x_1 + w_2x_2 + ... + w_dx_d + c \]
											</div>

											<p>In that case, we can update all of the <b>w</b>'s as </p>
										

											<h3>
												\[  \frac{\partial L(w_1, w_2, ..., w_d, c)}{\partial w_k} = \sum_{i=1}^N 2 x_k( f(\vec{w}, c)  - z_i) f(\vec{w}, c)(1-f(\vec{w}, c)) \]
											</h3>

											<h3>
												\[  \frac{\partial L(w_1, w_2, ..., w_d, c)}{\partial c} = \sum_{i=1}^N 2 ( f(\vec{w}, c)  - z_i) f(\vec{w}, c)(1-f(\vec{w}, c)) \]
											</h3>

											<p>
												where <b>w</b> with an arrow over it represents a vector of all <b>ws</b>
											</p>

											<h3>
												\[  f(\vec{w}, c) = f( w_1x_1 + w_2x_2 + ... + w_dx_d + c ) \]
											</h3>

											<HR>
												<h2><a name = "convexitylogistic">Convexity And Logistic Loss</a></h2>
												<p>
													This seems like it worked pretty well on the example we looked at, but there is a theoretical problem.  To get at it, let's look at a simpler example where something strange can happen.  In particular, let's setup the following data
													<ul>
														<li>
															2 points with a 0 label at <b>x=-1.8</b> and <b>x = -0.4</b>
														</li>
														<li>
															2 points with a 1 label at <b>x=-0.7</b> and <b>x = -0.8</b>
														</li>
													</ul>
												</p>

												<p>
													Let's suppose we take an <b>initial guess</b> of <b>a = 0, b = 0</b> for our parameters, and then we run gradient descent from that point in parameter space.  Here is what we get, which converges nicely to something with a squared loss of 0.891
												</p>

												<img src = "../Week11_Convexity_NNIntro/Nonconvex_1.gif">

												<p>
													However, if we start with an initial guess of <b>a = -7, be = -2</b>, we end up converging to a different local min with slightly higher loss
												</p>
												<img src = "../Week11_Convexity_NNIntro/Nonconvex_2.gif">

												<p>
													The problem here is that there are additional local mins of squared loss over the parameter space in addition to the global min.  If we're unlucky about our initial guess, we may end up in a non-optimal local min that's not a global min.  We could try starting at multiple different places and leading to the one which gives the best result, like we did in <a href = "../../Assignments/HW5a_3DShapeCluster/index.html#task3">K-Means clustering task 3</a>, but there is a better answer for logistic regression.
												</p>

												<h3><a name = "convexity">Convexity</a></h3>
												<p>
													The root of the issue for why we can end up with more than one local min is that the loss function we're using is <b>nonconvex</b>.  For example, the loss function of the centered logistic function if <b>y = 0</b> is 
												</p>

												<div style="width:200px;">
												<h3>
													\[ \left( \frac{1}{1+e^{-u}} \right)^2 \]
												</h3></div>

												<p>
													which is shown in a plot below 
												</p>
												
												<img src = "SquaredLoss0.svg" width=500>

												<p>
													A convex function has the property that a line segment between any pairs of points on the graph of the function stays <b>above</b> the graph.  We see that we can violate this with the squared logistic function, as shown by the example below (in which a line segment should always stay in the pink region above the graph if the function is convex)
												</p>

												<img src = "SquaredLoss0Convex.svg" width=500>

												<p>
													And the squared loss for <b>y = 1</b> looks exactly the same but reflected about the y-axis, so it has the same problem.  
												</p>

												<p>
													Let's devise another loss function that is convex, which we'll call <b>logistic loss</b>.  We'll start by taking the negative log of the logistic function 
												</p>

												<div style="width:200px;">
												<h3>
													\[ -\log(f(u)) = - \log\left( \frac{1}{1 + e^{-u}} \right) = \log (1 + e^{-u}) \]
												</h3>
												
												</div>

												<p>
													Here's what this looks like 
												</p>

												<img src = "LogisticLoss1.svg" width=500>
												

												<p>
													We see that this function actually is convex!  Also, if we are trying to solve for an input where the logistic function should be closest to 1 (i.e. we're on the positive side of the x-axis), then this loss function makes sense; we get an increasing penalty when we go in the negative direction and a very small penalty when we go in the positive direction.
												</p>

												<p>
													We can create a very similar loss function for the case when <b>y = 0</b> as 
												</p>

												<div style="width:200px;">
													<h3>
														\[ -\log(1-f(u))  \]
												</h3>
												</div>

												<p>
													Which will also be convex (like the squared loss, it is a reflection about the y-axis of the original function -log(f(u))).  Below is a plot comparing both squared loss functions 
												</p>

												<img src = "SquaredVsLogisticLoss.svg">
													
												<p>
													In addition to being convex, these loss functions have a really nice property that they always decrease as we get further away from the target value; that is, they don't suffer from the problem of <b>vanishing gradients</b> like the squared loss, which flattens out on both sides.  A vanishing gradient is a terrible thing if we're far on the wrong side, because the derivative may be numerically zero and we'll have no idea what direction we need to walk, but we're actually super far from where we need to be.
												</p>

												<p>
													Now let's put both of the logistic loss functions together into one final equation for logistic loss over the entire dataset.  We'll multiply the 1-loss term by y so that it's only active for <b>y = 1</b>, and we'll multiply the 0-loss term by (1-y) so it's only active for <b>y = 0</b>
												</p>

												<h4><a name = "logisticloss">Logistic Loss</a></h4>
												<div style="width:200px;">
												<h3>
													\[ L(a, b) = \sum_{i=1}^N -y_i \log(f(ax_i + b)) - (1-y_i)\log(1-f(ax_i+b)) \]
												</h3>
												</div>
													
												<p>									
													To show that the above function is convex, we use two properties of convex functions

													<ol>
														<li>
															The composition of convex functions is still convex
														</li>
														<li>
															The sum of convex functions is still convex
														</li>
													</ol>

													Our final loss function is the sum of compositions of individual convex functions with "affine functions" (e.g. ax + by + c or ax + by + cz + d), which are completely flat and hence also convex. So the whole thing is convex.
												</p>

												<p>
													Why do we care so much about convex functions though?  It's because they can have at most <b>a single minimum</b>.  This means that there's only one place gradient descent can converge to if we choose the step size correctly, so it doesn't matter where the min is with respect to our initial guess.
												</p>

												<h3><a name = "gradient">Taking The Gradient</a></h3>
												<p>
													Now that we know that using the logistic loss is a good idea, let's take its gradient so we can apply gradient descent.  Let's suppose we're taking the derivative with respect to some parameter <b>w</b> of which each parameter <b>u<SUB>i</SUB></b> is a function (such as the parameter <b>a</b> in <b>u<SUB>i</SUB> = ax<SUB>i</SUB> + by<SUB>i</SUB> + c</b>)
												</p>

												<div style="width:200px;">
													<h3>
														\[ \frac{\partial}{ \partial w} \left( \sum_{i=1}^N -y_i \log(f(u_i)) - (1-y_i)\log(1-f(u_i)) \right)  \]
													</h3>
													<h3>
														\[ = \sum_{i=1}^N \left( -y_i \frac{1}{f(u_i)}f(u_i)(1-f(u_i)) - (1-y_i)\frac{1}{1-f(u_i)}(-f(u_i)(1-f(u_i))) \right) \frac{\partial u_i}{\partial w} \]
													</h3>
												</div>

												<p>
													which can be simplified to 
												</p>

												<div style="width:200px;">
													<h3>
														\[ = \sum_{i=1}^N \left( -y_i (1-f(u_i)) + (1-y_i)f(u_i) \right) \frac{\partial u_i}{\partial w} \]
													</h3>
												</div>

												<p>
													Which simplifies quite nicely down to 
												</p>


												<div style="width:200px;">
													<h3>
														\[ = \sum_{i=1}^N (f(u_i) - y_i) \frac{\partial u_i}{\partial w} \]
													</h3>
												</div>

												<p>
													Since we move in the negative direction of the gradient in gradient descent, this translates into the rule 
												</p>

												<div style="width:200px;">
													<h3>
														\[ w \gets w + \alpha \sum_{i=1}^N (y_i - f(u_i)) \frac{\partial u_i}{\partial w} \]
													</h3>
												</div>

												<p>
													where <b>&alpha;</b> is the learning rate.  This is a super nice equation, and it's very intuitive!  What is says is we need to update a parameter at a rate proportional to the difference between the logistic function and the labels <b>y<SUB>i</SUB></b>.  For instance, if <b>y<SUB>i</SUB></b> is a 1 and <b>f(y<SUB>i</SUB>)</b> is close to 0, we need to move our parameter <b>w</b> in the positive direction.  Conversely, if <b>y<SUB>i</SUB></b> is a 0 and <b>f(y<SUB>i</SUB>)</b> is close to 1, we need to move <b>w</b> in a negative direction.
												</p>

												<p>
													To summarize for general high dimensional logistic regression, if 
												</p>

												<h3>
													\[  f(\vec{w}, c) = f(\vec{w} \cdot \vec{x}, c) = f( w_1x_1 + w_2x_2 + ... + w_dx_d + c ) \]
												</h3>

												Then the update rules are 
										

												<h3>
													\[  w_k \gets w_k + \alpha \sum_{i=1}^N x_k(y_i - f(\vec{w}, c)) \]
												</h3>
	
												<h3>
													\[  c \gets c + \alpha \sum_{i=1}^N (y_i - f(\vec{w}, c)) \]
												</h3>
	


												<p>
													Below is running this on the pathological example we started from the point that ended up with a non-optimal local min with squared loss.  As you can see, there's only one global min at the bottom of the hill
												</p>

												<img src = "../Week11_Convexity_NNIntro/Convex.gif">



	
												<h3><a name = "code">Code</a></h3>
												<p>
													The notebook below shows the code I used to generate the pathological example for a squared loss that has more than one local min.  You may find some useful tidbits in here for assignment 6.
												</p>
	
												<iframe src="LogisticLoss.html" width=800 height=800></iframe>


                                    
                                </div>
						</div>
					</div>

					<!--LaTeX in Javascript!-->
					<script src="../../../../jsMath/easy/load.js"></script>
					<!--Syntax highlighting in Javascript!-->
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shCore.js"></script>
					<script type="text/javascript" src="../../../syntaxhighlighter/scripts/shBrushJScript.js"></script>
                    <script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushCpp.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushXml.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushMatlabSimple.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushPython.js"></script>
					<link type="text/css" rel="stylesheet" href="../../../../syntaxhighlighter/styles/shCoreDefault.css"/>
					<script type="text/javascript">SyntaxHighlighter.all();</script>

<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
                                        <li>
											<span class="opener">General</span>
											<ul>
												<li><a href = "../../index.html#overview">Overview</a></li>
												<li><a href = "../../index.html#logistics">Technology Logistics</a></li>
												<li><a href = "../../index.html#deliverables">Deliverables</a></li>
												<li><a href = "../../index.html#debugging">Debugging Principles</a></li>
												<li><a href = "../../index.html#schedule">Schedule</a></li>
												<li><a href = "../../index.html#grading">Grading / Deadlines Policy</a></li>
												<li><a href = "../../index.html#environment">Classroom Environment</a></li>
												<li><a href = "../../index.html#collaboration">Collaboration Policy</a></li>
												<li><a href = "../../index.html#other">Other Resources / Policies</a></li>
											</ul> 
										</li>
										<li><a href = "../../Software/index.html">Software</a></li>
										<li><a href = "../../index.html#schedule">Schedule</a></li>
                                        <li>
											<span class="opener">Assignments</span>
											<ul>
												<li>
													<a href = "../../../Modules/Module1/Video1">HW0: Python Self Study Module</a>
												</li>
												<li>
													<a href = "../../Assignments/HW1_WelcomeToCS477">HW1: Welcome To CS 477</a>
												</li>
												
												<li>
													<a href = "../../Assignments/HW2_RushHour">HW2: The Rush Hour Problem</a>
												</li>
												<li>
													<a href = "../../Assignments/HW3_Markov">HW3: Markov Chains for Text Processing</a>
												</li>
												<!--
												<li>
													<a href = "../../Assignments/HW4_RobotLocalization">HW4: Bayesian Robot Localization</a>
												</li>
												<li>
													<a href = "../../Assignments/HW5a_3DShapeCluster">HW5a: 3D Shape Clustering</a>
												</li>
												<li>
													<a href = "../../Assignments/HW5b_Unsupervised">HW5b: NMF for Music Component Separation</a>
												</li>
												<li>
													<a href = "../../Assignments/HW6_LogisticRegression">HW6: Logistic Regression on Movie Reviews</a>
												</li>
												<li>
													<a href = "../../Assignments/HW7_DeepLearning">HW7: (Deep) Neural Networks on Images</a>
												</li>
												!-->
											</ul>
										</li>
                                        <li>
											<span class="opener">Class Exercises / Notes</span>
											<ul>
												<li>
													<a href = "../../ClassExercises/Week1_Bandit/index.html">Week 1: Introduction To Reinforcement Learning</a>
													<ul>
														<li>
															<a href = "../../ClassExercises/Week1_Bandit/jsbandit/index.html">The Multi-Armed Bandit Game</a>
														</li>
													</ul>
												</li>
												<li>
													<a href = "../../ClassExercises/Week1_Adventure">Week 1: Choose Your Own Adventure</a>
													<ul>
														<li><a href = "../../ClassExercises/Week1_Adventure/index.html#student">Student Adventures</a></li>
													</ul>
												</li>
												<li>
													<a href = "../../Materials/MazeExplorer">Week 2: Maze Searching Game</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week2_BasicSearch">Week 2: Blind Maze Searching</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week2_8Puzzle">Week 2: 8 Puzzle</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week3_PrioritySearch">Week 3: Uniform Cost, Greedy Best-First, and A* Search</a>
												</li>
												<li>
													<a href = "https://ursinus.instructure.com/courses/16260/assignments/186957">Week 3: An Admissible But Not Consistent Heuristic</a>
												</li>
												<li>
													<a href = "../../../Modules/Module2/Video1">Week 4: Probability Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week4_Markov">Week 4: Markov Chains of Characters</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week4_MarkovText">Week 4: Markov Chains for Document Representations</a>
												</li>
												<li>
													<a href = "https://ursinus.instructure.com/courses/16260/quizzes/24127">Week 4: Bayes Rule Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_NaiveBayes">Week 5: Bayes Rule And Naive Bayes Classifiers</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_BagOfWords">Week 5: Bag of Words Naive Bayes Exercise</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_KMeans">Week 5: KMeans Clustering And Visual Bag of Words</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week6_HMM">Week 5/6: Hidden Markov Models / Bayes Filtering / Viterbi Notes</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_RobotLocalization">Week 5/6: Robot Localization</a>
												</li>
												<li>
													<a href = "https://ursinus-cs477-f2023.github.io/Modules/HMM/Video1">Week 6: HMM Module</a>
												</li>
												<li>
													<a href = "../../../Modules/VectorModule/Video1">Week 7: Euclidean Vectors / Data Vectorization Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week7_DigitsNN.html">Week 7: K-Nearest Neighbors And Digits Classification</a>
												</li>
												<li>
													<a href = "../../../Modules/MatrixModule/Video1">Week 8: Matrix Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week10_LogisticRegression/index.html">Week 10/11: Logistic Regression And Gradient Descent</a>
												</li>
												
											</ul>
										</li>
										<li><a href = "../../Ethics/index.html">Ethics Reading / Discussions</a></li>
										<li><a href = "../../FinalProject/index.html">Final Ethics Project</a></li>
									</ul>
								</nav>


							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; <a href = "http://www.ctralie.com">Christopher J. Tralie</a>. All rights reserved.  Contact chris.tralie@gmail.com. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

			</div>
			
            <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
            <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- End Sidebar !-->

<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/skel.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="../../assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="../../assets/js/main.js"></script>
<!-- End Scripts -->
