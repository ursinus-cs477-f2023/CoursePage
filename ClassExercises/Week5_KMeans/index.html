<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<!-- Header !-->
	<head>
		<title>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<!--[if lte IE 8]><script src="../../assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="../../assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="../../assets/css/ie8.css" /><![endif]-->
        <style>
        .image_off, #home:hover .image_on{
           display:none
        }
        .image_on, #home:hover .image_off{
           display:block
        }
        </style>
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="../../index.html" class="logo"><strong>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</strong></a>
								</header>
<!-- End Header !-->

							<!-- Content -->
								<section>
									<header class="main">
                                        <h2>K-Means Clustering And Some Applications</h2>
                                        <h3><a href = "http://www.ctralie.com">Chris Tralie</a></h3>
									</header>

									<div id="page-content">

										<p>
											We're now going to consider an unsupervised algorithm that has a model of geometric structure in our data, namely a "cluster."  To get at it, let's generate and plot the following 2D dataset in matplotlib:
										</p>


										<script type="syntaxhighlighter" class="brush: python"><![CDATA[
											import numpy as np
											import matplotlib.pyplot as plt
											from scipy.spatial import KDTree # We'll use this later
											
											np.random.seed(0)
											N = 150
											X = np.random.randn(N, 2)
											X[0:50] += np.array([8, 0])
											X[100::] += np.array([4, 4])

											plt.scatter(X[:, 0], X[:, 1])
											plt.axis("equal")
										</script>  



										<img src = "Cluster.svg">

										<p>
											It looks like there are three distinct groups, or "clusters" of points here.  As it turns out, making this notion precise is quit challenging, and there are many models for what constitutes a cluster.  But at this stage of the course, we'll consider a constructive model of a cluster by following a simple geometric algorithm known as <b>KMeans Clustering</b>.  The steps are as follows:
										</p>
										
										<div style="background-color: blanchedalmond; padding:20px;">
										<h3>Algorithm: KMeansClustering(X, K)</h3>
										<p>
											Where <b>X</b> is a set of <b>N</b> points in <b>d</b> Euclidean dimensions, which we're representing as a data matrix above, and <b>K &lt; N</b> is some a priori number of clusters that we think are in the data
										</p>
										<ol>
											<li>Choose <b>K</b> random points in the dataset called <b>centers</b></li>
											<li>
												For each data point <b>x<SUB>i</SUB></b> &in; <b>X</b>, find the nearest cluster center, according to some distance
											</li>
											<li>
												Replace the coordinates each cluster center with the mean of the points that were closest to that center.
											</li>
											<li>
												Repeat steps 2 and 3 for some number of iterations
											</li>
										</ol>
										</div>

										<p>
											Below is an animation showing successive applications of steps 2 and 3 on the above data, assuming that there are 3 clusteres
										</p>

										<img src = "ClusterProcess.gif">

										<p>
											At some point, we <b>converge</b>; that is, the assignment of points to cluster centers remains fixed, and so the updated cluster centers don't change.  It only takes 4 iterations for us to converge in the above example:
										</p>
										<img src = "ClusterResults.svg">

										<p>
											<b>Your task:</b> Implement KMeans clustering to find the clusters of the above point set.  What happens when you choose <b>K = 2</b> vs <b>K = 3</b> vs <b>K = 4</b>?
										</p>

										<HR>
											<h3><a name = "hints">Algorithm Hints</a></h3>

											<h4>Step 1: Choosing Random Points As Cluster Centers</h4>
											<p>
												Let's suppose that we store <b>N</b> points in <b>d</b> dimensions in an <b>N x d</b> <a href = "https://ursinus-cs477-f2021.github.io/Modules/VectorModule/Video3">data matrix</a> <code>X</code>, and that we will store the <b>n_clusters</b> cluster centers in an <b>n_clusters x d</b> data matrix called <code>clusters</code>.  Then, as we discussed in class, we can use the following code for step 1
											</p>

											<script type="syntaxhighlighter" class="brush: python"><![CDATA[
												# Pick some disjoint random indices of points to start 
												# with for a cluster
												idxs = np.random.permutation(X.shape[0])[0:n_clusters]
												clusters = []
												for idx in idxs:
													clusters.append(X[idx, :]) # Pull out the next random point and put it into the clusters array 
												clusters = np.array(clusters) # Convert 2D list into an official numpy array so we can do 2D slicing
											</script>  

											<p>
												Actually, there's a super slick shortcut we can use in numpy to do index-based selection, turning this into a 2-liner
											</p>

											<script type="syntaxhighlighter" class="brush: python"><![CDATA[
												# Pick some disjoint random indices of points to start 
												# with for a cluster
												idxs = np.random.permutation(X.shape[0])[0:n_clusters]
												clusters = X[idxs, :] # Create an n_clusters x d 
											</script>  

											<h4>Step 2: Finding Nearest Cluster Centers</h4>

											<p>
												Here's one option for pseudocode that finds the index <b>j</b> in the clusters list of the closest cluster center to each <b>x<SUB>i</SUB></b>
											</p>

											<div style="background-color: blanchedalmond; padding: 10px; width:600px;">

												<ul>
													<li>
														For each <b>x<SUB>i</SUB> &in; X</b>
														<ul>
															<li>Let <b>min_dist</b> = infinity (<code>np.inf</code> in numpy)</li>
															<li>Let <b>min_index</b> = 0</li>
															<li>For each cluster <b>c<SUB>j</SUB> &in; clusters</b>
																<ul>
																	<li>Let <b>d</b> = dist(<b>x<SUB>i</SUB></b>, <b>c<SUB>j</SUB></b>)</li>
																	<li>
																		If <b>d &lt; min_dist</b>
																		<ul>
																			<li>
																				<b>min_dist = d</b>
																			</li>
																			<li>
																				<b>min_index = j</b>
																			</li>
																		</ul>
																	</li>
																</ul>
															</li>
														</ul>
													</li>
												</ul>
											</div>

											<p>
												We also have to think how we would compute a distance in high Euclidean dimensions.  If you recall in the module on <a href = "https://ursinus-cs477-f2021.github.io/Modules/VectorModule/Video3">data vectorization</a>, the magnitude of a vector is the square root of the sum of the squares of its components. 
											</p>

											<div style="width:100px;">
												<h3>
													\[ |\vec{v}| = \sqrt{\sum_{i = 1}^d \vec{v}_i^2} \]
												</h3>
											</div>

											<p>
												Which, in 2D (d = 2), reduces to the familiar pythagorean theorem for a right triangle with one side length along the x component and one side length along the y component
											</p>

											<div style="width:100px;">
												<h3>
													\[ |\vec{v}| = \sqrt{x^2 + y^2} \]
												</h3>
											</div>

											<p>
												To compute the distance between two vectors, we compute the magnitude/length of the vector between them.  This vector is obtained via a vector subtraction, so the final formula is the square root of the sum of the squared differences between parallel dimensions between the two vectors"
											</p>

											<div style="width:100px;">
												<h3>
													\[ |\vec{u} - \vec{v}| = \sqrt{\sum_{i = 1}^d (\vec{u}_i - \vec{v}_i)^2} \]
												</h3>
											</div>

											<p>
												In 2D (d = 2), this reduces to 
											</p>

											<div style="width:100px;">
												<h3>
													\[ |(a, b) - (c, d)| = \sqrt{ (a-c)^2 + (d-b)^2 } \]
												</h3>
											</div>

											<p>
												Actually, there's a slick way to compute this using numpy's linear algebra library for two different vectors <code>x</code> and <code>y</code>
											</p>

											<script type="syntaxhighlighter" class="brush: python"><![CDATA[
												from numpy import linalg
												d = linalg.norm(x-y)
											</script> 

											<h4>Step 3: Computing Means</h4>
											<p>
												See the notes on <a href = "../Week10_NumpyTricks/NumpyTricks.html">numpy tricks</a> from week 10 on a slick way to do this.
											</p>
										

										<HR>
											<h3><a name = "imagecartoons">Application: Image Quantization / Cartoonization</a></h3>

										<p>
											There are some cool applications in image processing, which I wrote a <a href = "https://writings.stephenwolfram.com/2017/11/what-is-a-computational-essay/">computational essay</a> about below (<a href = "QuantizationCartoons.ipynb">Click here</a> to download the jupyter file and <a href = "theo.jpg">here</a> to download the image I was using)
										</p>

										<iframe src = "QuantizationCartoons.html" width=100% height=7000></iframe>


										<HR>
											<h3><a name = "visualbow">Application: Visual Bag of Words</a></h3>
											<iframe src = "VisualBOW.html" width=100% height=5200></iframe>
										




                                    
                                </div>
						</div>
					</div>

					<!--LaTeX in Javascript!-->
					<script src="../../../../jsMath/easy/load.js"></script>
					<!--Syntax highlighting in Javascript!-->
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shCore.js"></script>
					<script type="text/javascript" src="../../../syntaxhighlighter/scripts/shBrushJScript.js"></script>
                    <script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushCpp.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushXml.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushMatlabSimple.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushPython.js"></script>
					<link type="text/css" rel="stylesheet" href="../../../../syntaxhighlighter/styles/shCoreDefault.css"/>
					<script type="text/javascript">SyntaxHighlighter.all();</script>

<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
                                        <li>
											<span class="opener">General</span>
											<ul>
												<li><a href = "../../index.html#overview">Overview</a></li>
												<li><a href = "../../index.html#logistics">Technology Logistics</a></li>
												<li><a href = "../../index.html#deliverables">Deliverables</a></li>
												<li><a href = "../../index.html#debugging">Debugging Principles</a></li>
												<li><a href = "../../index.html#schedule">Schedule</a></li>
												<li><a href = "../../index.html#grading">Grading / Deadlines Policy</a></li>
												<li><a href = "../../index.html#environment">Classroom Environment</a></li>
												<li><a href = "../../index.html#collaboration">Collaboration Policy</a></li>
												<li><a href = "../../index.html#other">Other Resources / Policies</a></li>
											</ul> 
										</li>
										<li><a href = "../../Software/index.html">Software</a></li>
										<li><a href = "../../index.html#schedule">Schedule</a></li>
                                        <li>
											<span class="opener">Assignments</span>
											<ul>
												<li>
													<a href = "../../../Modules/Module1/Video1">HW0: Python Self Study Module</a>
												</li>
												<li>
													<a href = "../../Assignments/HW1_WelcomeToCS477">HW1: Welcome To CS 477</a>
												</li>
												
												<li>
													<a href = "../../Assignments/HW2_RushHour">HW2: The Rush Hour Problem</a>
												</li>
												<li>
													<a href = "../../Assignments/HW3_Markov">HW3: Markov Chains for Text Processing</a>
												</li>
												<li>
													<a href = "../../Assignments/HW4_FundamentalFreq">HW4: Fundamental Frequency Tracking And Pitch-Based Audio Effects</a>
													<ul>
														<li>
															<a href = "../../Assignments/HW4_FundamentalFreq/statements.html">Musical statements</a>
														</li>
													</ul>
												</li>
												<li>
													<a href = "../../Assignments/HW5_LogisticRegression">HW5: Logistic Regression on Movie Reviews</a>
												</li>
												<li>
													<a href = "../../Assignments/HW6_BYOMLP">HW6: Build Your Own Multilayer Perceptron (BYOMLP)</a>
												</li>
												<!--
												<li>
													<a href = "../../Assignments/HW7_DeepLearning">HW7: (Deep) Neural Networks on Images</a>
												</li>
												!-->
											</ul>
										</li>
                                        <li>
											<span class="opener">Class Exercises / Notes</span>
											<ul>
												<li>
													<a href = "../../ClassExercises/Week1_Bandit/index.html">Week 1: Introduction To Reinforcement Learning</a>
													<ul>
														<li>
															<a href = "../../ClassExercises/Week1_Bandit/jsbandit/index.html">The Multi-Armed Bandit Game</a>
														</li>
													</ul>
												</li>
												<li>
													<a href = "../../ClassExercises/Week1_Adventure">Week 1: Choose Your Own Adventure</a>
													<ul>
														<li><a href = "../../ClassExercises/Week1_Adventure/index.html#student">Student Adventures</a></li>
													</ul>
												</li>
												<li>
													<a href = "../../Materials/MazeExplorer">Week 2: Maze Searching Game</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week2_BasicSearch">Week 2: Blind Maze Searching</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week2_8Puzzle">Week 2: 8 Puzzle</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week3_PrioritySearch">Week 3: Uniform Cost, Greedy Best-First, and A* Search</a>
												</li>
												<li>
													<a href = "https://ursinus.instructure.com/courses/16260/assignments/186957">Week 3: An Admissible But Not Consistent Heuristic</a>
												</li>
												<li>
													<a href = "../../../Modules/Module2/Video1">Week 4: Probability Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week4_Markov">Week 4: Markov Chains of Characters</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week4_MarkovText">Week 4: Markov Chains for Document Representations</a>
												</li>
												<li>
													<a href = "https://ursinus.instructure.com/courses/16260/quizzes/24127">Week 4: Bayes Rule Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_NaiveBayes">Week 5: Bayes Rule And Naive Bayes Classifiers</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_BagOfWords">Week 5: Bag of Words Naive Bayes Exercise</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week6_HMM">Week 5/6: Hidden Markov Models / Bayes Filtering / Viterbi Notes</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_RobotLocalization">Week 5/6: Robot Localization</a>
												</li>
												<li>
													<a href = "https://ursinus-cs477-f2023.github.io/Modules/HMM/Video1">Week 6: HMM Module</a>
												</li>
												<li>
													<a href = "https://github.com/ursinus-cs477-f2023/Week6_MDP">Week 6: Markov Decision Processes And Pong AI</a>
												</li>
												<li>
													<a href = "../../../Modules/VectorModule/Video1">Week 7: Euclidean Vectors / Data Vectorization Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week7_DigitsNN/index.html">Week 7: K-Nearest Neighbors And Digits Classification</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_KMeans">Week 7: KMeans Clustering And Visual Bag of Words</a>
												</li>
												<li>
													<a href = "../../../Modules/MatrixModule/Video1">Week 7: Matrix Module</a>
												</li>
												<li>
													<a href = "ClassExercises/Week7_PCA/Week7_PCA/UnsupervisedDigits.html">Week 7: PCA on MNIST Digits</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week10_LogisticRegression/index.html">Week 8: Logistic Regression And Gradient Descent</a>
												</li>
												<li>
													<a href = "../../../Modules/LogisticRegression/Video1">Week 8: Neural Networks Module 1</a>
												</li>
												<li>
													<a href = "../../../Modules/Softmax/Video1">Week 9: Softmax Module</a>
												</li>
												<li><a href = "../../../Modules/NeuralNets/Video0">Week 9/10: Multi-Class Logistic Regression And Feedforward Neural Nets Module</a></li>
												<li>
													<a href = "../../ClassExercises/Week10_Backprop/index.html">Week 10: Backpropagation on Multilayer Perceptrons</a>
												</li>
												<li>
													<a href = "../../../Modules/Backprop/Video1">Week 10: Backpropagation Module</a>
												</li>
												
												
											</ul>
										</li>
										<li><a href = "../../Ethics/index.html">Ethics Reading / Discussions</a></li>
										<li><a href = "../../FinalProject/index.html">Final Ethics Project</a></li>
									</ul>
								</nav>


							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; <a href = "http://www.ctralie.com">Christopher J. Tralie</a>. All rights reserved.  Contact chris.tralie@gmail.com. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

			</div>
			
            <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
            <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- End Sidebar !-->

<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/skel.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="../../assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="../../assets/js/main.js"></script>
<!-- End Scripts -->
