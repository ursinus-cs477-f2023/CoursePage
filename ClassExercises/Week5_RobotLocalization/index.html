<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<!-- Header !-->
	<head>
		<title>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<!--[if lte IE 8]><script src="../../assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="../../assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="../../assets/css/ie8.css" /><![endif]-->
        <style>
        .image_off, #home:hover .image_on{
           display:none
        }
        .image_on, #home:hover .image_off{
           display:block
        }
        </style>
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="../../index.html" class="logo"><strong>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</strong></a>
								</header>
<!-- End Header !-->

							<!-- Content -->
								<section>
									<header class="main">
                                        <h2>Bayesian Robot Localization</h2>
                                        <h3><a href = "http://www.ctralie.com">Chris Tralie</a></h3>
									</header>

									<div id="page-content">
										<ul>
											<li><a href = "#noisemodel">Noise Model</a></li>
											<li><a href = "#sensormodel">Observation Probabilities</a></li>
										</ul>
										<a href = "#programming">Programming Tasks</a>
										<ul>
											<li><a href = "#filtering">Task 1: Online Position Tracking with Bayes Filtering</a></li>
											<li><a href = "#viterbi">Task 2: Offline Position Tracking with Viterbi</a></li>
										</ul>

                                        <p>
											The purpose of this exercise is to track a robot through an environment from noisy measurements using Bayesian algorithms from "<a href = "../Week6_HMM/">Hidden Markov Models (HMMs)</a>."  In this case, the hidden states are the <b>position of a robot in 2D</b>, and the observations are <b>omnidirectional range scans</b>.  This is an idealized model of a real "LIDAR scanner" such as the <a href = "https://hokuyo-usa.com/products/lidar-obstacle-detection/urg-04lx">Hokuyo URG-04LX laser range scanner</a>, which is able to sweep a laser in a 270 degree field of view in front of it
										</p>

										<img src = "URG-04LX.jpg" width=250>

										<p>
											For this exercise, I've created a synthetic robot that can move right/left/up/down on a 2D grid, and which is always oriented the same way.  Below is an image of this robot moving around.  The ground truth position of the robot (the hidden state) is shown on the left on a map of the environment, while the laser scan (observation) is shown in the middle.  The right shows the scan as stored in an array, which is what you'll be manipulating in code. There is an index in the array for each angle of the scan, and the value at the index corresponds to the range at that angle.  0 degrees is the first element, and 360 degrees is the last element, so you'll notice how the ranges loop around at the boundaries
										</p>

										<img src = "clean_scan.gif">

										<h4><a name = "noisemodel">Noise Model</a></h4>
										<p>
											The above is an idealized example, however, because the scan is rarely this perfect.  Usually there is noise that <i>perturbs</i> the true range measurements; that is, we end up measuring that a wall is either closer or further than it actually is at a particular angle.  We'll model the noise here as a multiplicative Gaussian; that is, if the ground truth range is <b>r</b>, then the observed range <b>m(r)</b> is 
										</p>

										<h3>
											\[ m(r) = r(1 + \alpha n)\]
										</h3>

										<p>
											where <b>n</b> is a "standard Gaussian distributed" random variable with distribution 
										</p>

										<h3>
											\[ n \sim \frac{1}{\sqrt{2 \pi}} e^{-n^2/2} \]
										</h3>

										<p>
											and <b>&alpha;</b> is some parameter set ahead of time.  In other words, the further away the measurement is, the more it can be perturbed.  Below is the code I used to sample from this noise model, taking advantage of numpy's built in <code><a href = "https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html">randn</a></code> method for sampling random variables from the standard Gaussian
										</p>

										<script type="syntaxhighlighter" class="brush: python"><![CDATA[
											scan[i] = range*(1+alpha*np.random.randn())
										</script>  

										<p>
											Below is an example where <b>&alpha; = 0.1</b>
										</p>

										<img src = "noisy_scan.gif">

										<p>
											Below is an example where <b>&alpha; = 4</b>
										</p>

										<img src = "verynoisy_scan.gif">

										<p>
											At this level of noise, it seems like we're hardly getting any useful information.  However, amazingly, if you use the above sensor model and assume that the robot is equally likely to visit any of its neighbors, then you can actually recover an excellent estimate of the robot's trajectory using the Viterbi algorithm.  Below is a plot of the original trajectory next to what the algorithm recovered here (NOTE: results may vary based on the noise samples):
										</p>

										<img src = "Est_Maze1_VeryNoisy.svg">

										<p>
											The estimated trajectory is perfect in this example!  This is the power of <b>sequence modeling</b>; even if our measurements are total crap at a particular instant in time, if they have even a little bit of signal, then we can "boost" the signal strength by looking at many states in sequence.
										</p>


										<h3><a name = "sensormodel">Observation Probabilities</a></h3>

										<p>
											The first step in gathering all of the components that are needed for an HMM is to come up with probabilities in an observation/measurement model.  Let's let <b>r<SUB>i</SUB></b> be the perfect range measurement of the i<SUP>th</SUP> angle at a particular location, and let <b>x<SUB>i</SUB></b> be the corresponding measurement at that angle, sampled according to the <a href = "#noisemodel">model above</a>. Then the probability density of the measured range <b>x<SUB>i</SUB></b> in terms of <b>r<SUB>i</SUB></b> is 
										</p>

										<h2>
											\[ p(x_i | r_i) = \frac{1}{\sqrt{2 \pi }(\alpha r_i + \gamma)} e^{-\frac{(x_i-r_i)^2}{2 (\alpha r_i + \gamma)^2}} \]
										</h2>

										<p>
											where <b>&gamma;</b> is a small number to prevent numerical divide by 0 for ranges that are too closes or noise that is too small.  In this assignment, we'll let <b>&gamma; = 0.1</b>.  Notice how based on the denominator of the exponent, ranges which are further have a higher probability density for the same deviation.  This is another way of seeing that the noise is worse for large distances.
										</p>
										<p>
											Assuming that the angles are all independent of each other, the joint probability of all of the angles in a single scan can be written as the product of all such probabilities at each angle.  
										</p>

										<p>
											Let's think about which states would have a high probability given particular measurements.  Below is an image showing an observed scan with its ground truth position indicated as a blue dot on the map, as well as two ideal scans at different positions shown at their state locations as orange and green dots on the map
										</p>

										<p>
											The orange dot is very close to the measured location, so its scan looks pretty similar.  The green dot is far and in a region that looks nothing like the region where the measurement was taken, so its scan is very different.  We can see the differences in the plot of the scans.  Each angle contributes a probability as in the above equation.  Because of the negative exponential which contains <b>-(x<SUB>i</SUB> - r<SUB>i</SUB>)<SUP>2</SUP></b>, the probability density at a particular angle peaks when <b>x<SUB>i</SUB> = r<SUB>i</SUB></b>, and it falls off the further apart they are. So we will incur large penalties in the product for angles that have very different range measurements compared to what should be seen at a state under consideration.  These bad angle measurements will drag all of the rest down in the product.
										</p>

										<img src = "ScanExamples.svg">


										<p>
											I provided a method called <code>get_measurement_prob</code> that takes in a ground truth scan array, a measured scan array, and the noise value &alpha;, and which returns the probability density that a set of measured angles jointly occurred at a particular location.  For example, let's suppose we had some measurements with <b>&alpha;=0.1</b>.  Then running the following cell
										</p>

										<script type="syntaxhighlighter" class="brush: python"><![CDATA[
											K = len(state_scans)
											# Compute the measurement probability of the scan at each location
											meas_probs = np.zeros(K)
											idx = 55
											for i in range(K):
												meas_probs[i] = get_measurement_prob(observed_scans[idx], state_scans[i], alpha)
											# Plot the measurement probabilities on the map
											env.plot_probabilities(meas_probs, p=1e-2, show_max=False)
											# Plot the ground truth location from the trajectory as an green dot
											plt.scatter([X[idx, 0]], X[idx, 1], c='C2') 
											plt.legend(["Ground Truth Location"])
										</script> 

										<p>
											would generate the following plot
										</p>

										<img src = "MeasurementProbs.svg">

										<p>
											The brighter the cell, the higher the probability is relative to cells at other locations.  You'll notice here that for this particular location (shown in green), it has a high probability around the true location, but it also has a high probability towards the right side of similarly shaped narrow horizontal hallways.  As you will see in the tasks below, this kind of confusion can get resolved by tracking measurements over time.
										</p>

										<HR>
											<h2><a name = "programming">Programming Tasks</a></h2>

											<h3><a name = "gettingstarted">Getting Started</a></h3>
											<p>
												<a href = "https://github.com/ursinus-cs477-f2023/Week5_RobotLocalization/archive/refs/heads/main.zip">Click here</a> to download the starter code for this exercise.  
											</p>
											
										<p></p>



										<h3><a name = "filtering">Task 1: Online Position Tracking</a></h3>
										<p>
											You now have all of the ingredients you need to do an online tracking of the robot positions as new measurements come in!  You can assume the following two things:
											<ul>
												<li>The robot is equally likely to transition to any of its neighbors.  You can look up the neighbors of position <code>i</code> with <code>env.neighbors[i]</code></li>
												<li>The robot is equally likely to start at any position on the grid.  This implies that the initial probabilities for each state are <b>1/K</b>, where <b>K</b> is the number of states.</li>
											</ul>
											<h4>Your Task</h4>
											Given all of this information and the measurement model from before, implement <a href = "../../ClassExercises/Week6_HMM/index.html#bayespseudocode">Bayes filtering</a>  to track the position over time.  <b>Be sure to normalize the probabilities at each step so that they all sum to 1!</b>  Also, when summing up the transition probabilities from previous states, <b>only consider states which are neighbors of the state you're transitioning to</b>.  Otherwise, the program will have <b>O(TK<SUP>2</SUP>)</b> complexity instead of <b>O(TK)</b> complexity, and your code will go <b>very slowly</b>.  
										</p>
										
										
										<p>
											If you've implemented filtering properly, here's what you should see on the trajectory example we've been looking at with <b>&alpha;=4</b> (the actual position is shown as a blue dot, while the maximum probability is shown as a <span style="color:green">X</span>)
										</p>

										<img src = "Maze1_Tracking.gif">

										<p>
											You'll notice some cool things here, how the probability is distributed over all of the cells at first, but how it quickly hones in on the actual location of the robot.  You'll also see it hedging its bets between different long and narrow hallways when it happens to be in one, but as soon as it turns a corner or passes a fork in the road, the ambiguity is resolved.
										</p>

										<p>
											Here's another neat example where you see it gets very confused and estimates it's at the top row instead of the second to the bottom row for a while because of how similar all of the hallways look.  The ambiguity is mostly resolved once the robot turns the corner
										</p>

										<script type="syntaxhighlighter" class="brush: python"><![CDATA[
											env = Environment("Maze2.png")
											res = 50
											X = env.simulate_trajectory([[10, 45], [120, 45], [126, 100]])
											alpha = 4
											np.random.seed(0)
											observed_scans = []
											for i in range(X.shape[0]):
												observed_scans.append(env.get_range_scan(X[i, :], res, alpha))
											# These scans will take a second to generate on this map, so 
											# be sure to just run this cell once at the beginning
											state_scans = env.get_state_scans(res)
											## TODO: Make a new filtering model and try it out
										</script>

										<img src = "Maze2_Tracking.gif">

										<p>
											Here is an example that Marcos Maciel created in Fall 2021:
										</p>
										<img src = "marcos.gif">


										<h3><a name = "viterbi">Task 2: Offline Position Tracking</a></h3>

										<p>
											As you can see, filtering can get confused at individual steps, and we know if we can do things <i>offline</i> (i.e. we have access to <i>all measurements</i> over time), we can maximize the <i>joint probability</i> over the whole trajectory using the <a href = "../../ClassExercises/Week6_HMM/index.html#viterbipseudocode">Viterbi algorithm</a>.  This will fix things up so the trajectory doesn't jitter around as much locally, since it enforces consistency of the whole trajectory.  
										</p>
										<p>
											<h4>Your Task</h4> 
											Implement the Viterbi algorithm to compute an optimal sequence of state indices given an array of measurements.  Since you'll be accumulating over many states, be sure to add <b>log likelihoods</b>, as <a href = "../../ClassExercises/Week6_HMM/#viterbi">explained in the notes</a> rather than multiplying probabilities.
										</p>

										<p>
											<a name = "logmeasnote">NOTE: </a>
											If you use the same measurement probability function as you did in the last section and then you take the log, you might suffer from underflow and get complaints about taking the log of 0.  Instead, you should create a different version of your measurement function where you use a different analytical expression to compute the log probability directly.  You can use the following three facts about logs:
											<div style="width:100px;">
												<ul>
													<li>
														\[ \log(AB) = \log(A) + \log(B) \]
													</li>
													<li>
														\[ \log \left( \frac{1}{x} \right) = -\log(x) \]
													</li>
													<li>
														\[ e^{\log(x)} = x,  \log(e^x) = x \]
													</li>
												</ul> 
											</div>

											Taken together, this means that
										</p>

										<div style="width:300px;">
											<h3>
												\[ \log \left(  \left( \frac{1}{\sqrt{2 \pi }(\alpha r_i + \gamma)} \right) e^{ -\frac{(x_i-r_i)^2}{2(\alpha r_i + \gamma)^2}} \right) = -\log \left( \sqrt{2 \pi }(\alpha r_i + \gamma) \right) -\frac{(x_i-r_i)^2}{2(\alpha r_i + \gamma)^2} \]
											</h3>
										</div>
										

										

										<p>
											If your code works properly, you should get perfect results with &alpha;=4 on Maze1.png
										</p>

										<img src = "Est_Maze1_VeryNoisy.svg">

										<p>
											You should also get nearly perfect results with &alpha; = 4 for the trajectory on the second map
										</p>

										<img src = "Est_Maze2_VeryNoisy.svg">


										<h3>For The Bored...</h3>
										<p>
											If you finish this early, here are a few things you can try
										</p>
										<ul>
											<li>
												In addition to modeling the position, allow the robot to rotate.  How would you change your state space?  How would you update your observations to handle a rotation?
											</li>
											<li>
												The above is going to blow up the state space in memory.  Think of how you could use a <a href = "https://web.mit.edu/16.412j/www/html/Advanced%20lectures/Slides/Hsaio_plinval_miller_ParticleFiltersPrint.pdf">particle filter</a> to address this.
											</li>
											<li>
												Think about how you might store some "second order" information about where the robot has been like velocity.  If we assume the law of inertia, the robot is more likely to continue moving in the direction of its velocity than it is to make a sudden turn, so you can use non-uniform transition probabilities to neighbors.
											</li>
										</ul>


                                    
                                </div>
						</div>
					</div>

					<!--LaTeX in Javascript!-->
					<script src="../../../../jsMath/easy/load.js"></script>
					<!--Syntax highlighting in Javascript!-->
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shCore.js"></script>
					<script type="text/javascript" src="../../../syntaxhighlighter/scripts/shBrushJScript.js"></script>
                    <script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushCpp.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushXml.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushMatlabSimple.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushPython.js"></script>
					<link type="text/css" rel="stylesheet" href="../../../../syntaxhighlighter/styles/shCoreDefault.css"/>
					<script type="text/javascript">SyntaxHighlighter.all();</script>

<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
                                        <li>
											<span class="opener">General</span>
											<ul>
												<li><a href = "../../index.html#overview">Overview</a></li>
												<li><a href = "../../index.html#logistics">Technology Logistics</a></li>
												<li><a href = "../../index.html#deliverables">Deliverables</a></li>
												<li><a href = "../../index.html#debugging">Debugging Principles</a></li>
												<li><a href = "../../index.html#schedule">Schedule</a></li>
												<li><a href = "../../index.html#grading">Grading / Deadlines Policy</a></li>
												<li><a href = "../../index.html#environment">Classroom Environment</a></li>
												<li><a href = "../../index.html#collaboration">Collaboration Policy</a></li>
												<li><a href = "../../index.html#other">Other Resources / Policies</a></li>
											</ul> 
										</li>
										<li><a href = "../../Software/index.html">Software</a></li>
										<li><a href = "../../index.html#schedule">Schedule</a></li>
                                        <li>
											<span class="opener">Assignments</span>
											<ul>
												<li>
													<a href = "../../../Modules/Module1/Video1">HW0: Python Self Study Module</a>
												</li>
												<li>
													<a href = "../../Assignments/HW1_WelcomeToCS477">HW1: Welcome To CS 477</a>
												</li>
												
												<li>
													<a href = "../../Assignments/HW2_RushHour">HW2: The Rush Hour Problem</a>
												</li>
												<li>
													<a href = "../../Assignments/HW3_Markov">HW3: Markov Chains for Text Processing</a>
												</li>
												<li>
													<a href = "../../Assignments/HW4_FundamentalFreq">HW4: Fundamental Frequency Tracking And Pitch-Based Audio Effects</a>
													<ul>
														<li>
															<a href = "../../Assignments/HW4_FundamentalFreq/statements.html">Musical statements</a>
														</li>
													</ul>
												</li>
												<li>
													<a href = "../../Assignments/HW5_LogisticRegression">HW5: Logistic Regression on Movie Reviews</a>
												</li>
												<!--
												<li>
													<a href = "../../Assignments/HW7_DeepLearning">HW7: (Deep) Neural Networks on Images</a>
												</li>
												!-->
											</ul>
										</li>
                                        <li>
											<span class="opener">Class Exercises / Notes</span>
											<ul>
												<li>
													<a href = "../../ClassExercises/Week1_Bandit/index.html">Week 1: Introduction To Reinforcement Learning</a>
													<ul>
														<li>
															<a href = "../../ClassExercises/Week1_Bandit/jsbandit/index.html">The Multi-Armed Bandit Game</a>
														</li>
													</ul>
												</li>
												<li>
													<a href = "../../ClassExercises/Week1_Adventure">Week 1: Choose Your Own Adventure</a>
													<ul>
														<li><a href = "../../ClassExercises/Week1_Adventure/index.html#student">Student Adventures</a></li>
													</ul>
												</li>
												<li>
													<a href = "../../Materials/MazeExplorer">Week 2: Maze Searching Game</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week2_BasicSearch">Week 2: Blind Maze Searching</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week2_8Puzzle">Week 2: 8 Puzzle</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week3_PrioritySearch">Week 3: Uniform Cost, Greedy Best-First, and A* Search</a>
												</li>
												<li>
													<a href = "https://ursinus.instructure.com/courses/16260/assignments/186957">Week 3: An Admissible But Not Consistent Heuristic</a>
												</li>
												<li>
													<a href = "../../../Modules/Module2/Video1">Week 4: Probability Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week4_Markov">Week 4: Markov Chains of Characters</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week4_MarkovText">Week 4: Markov Chains for Document Representations</a>
												</li>
												<li>
													<a href = "https://ursinus.instructure.com/courses/16260/quizzes/24127">Week 4: Bayes Rule Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_NaiveBayes">Week 5: Bayes Rule And Naive Bayes Classifiers</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_BagOfWords">Week 5: Bag of Words Naive Bayes Exercise</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week6_HMM">Week 5/6: Hidden Markov Models / Bayes Filtering / Viterbi Notes</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_RobotLocalization">Week 5/6: Robot Localization</a>
												</li>
												<li>
													<a href = "https://ursinus-cs477-f2023.github.io/Modules/HMM/Video1">Week 6: HMM Module</a>
												</li>
												<li>
													<a href = "https://github.com/ursinus-cs477-f2023/Week6_MDP">Week 6: Markov Decision Processes And Pong AI</a>
												</li>
												<li>
													<a href = "../../../Modules/VectorModule/Video1">Week 7: Euclidean Vectors / Data Vectorization Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week7_DigitsNN/index.html">Week 7: K-Nearest Neighbors And Digits Classification</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_KMeans">Week 7: KMeans Clustering And Visual Bag of Words</a>
												</li>
												<li>
													<a href = "../../../Modules/MatrixModule/Video1">Week 7: Matrix Module</a>
												</li>
												<li>
													<a href = "ClassExercises/Week7_PCA/Week7_PCA/UnsupervisedDigits.html">Week 7: PCA on MNIST Digits</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week10_LogisticRegression/index.html">Week 8: Logistic Regression And Gradient Descent</a>
												</li>
												<li>
													<a href = "../../../Modules/LogisticRegression/Video1">Week 8: Neural Networks Module 1</a>
												</li>
												<li>
													<a href = "../../../Modules/Softmax/Video1">Week 9: Softmax Module</a>
												</li>
												<li><a href = "../../../Modules/NeuralNets/Video0">Week 9/10: Multi-Class Logistic Regression And Feedforward Neural Nets Module</a></li>
												
												
											</ul>
										</li>
										<li><a href = "../../Ethics/index.html">Ethics Reading / Discussions</a></li>
										<li><a href = "../../FinalProject/index.html">Final Ethics Project</a></li>
									</ul>
								</nav>


							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; <a href = "http://www.ctralie.com">Christopher J. Tralie</a>. All rights reserved.  Contact chris.tralie@gmail.com. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

			</div>
			
            <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
            <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- End Sidebar !-->

<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/skel.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="../../assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="../../assets/js/main.js"></script>
<!-- End Scripts -->
