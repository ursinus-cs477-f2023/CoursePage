<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<!-- Header !-->
	<head>
		<title>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<!--[if lte IE 8]><script src="../../assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="../../assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="../../assets/css/ie8.css" /><![endif]-->
        <style>
        .image_off, #home:hover .image_on{
           display:none
        }
        .image_on, #home:hover .image_off{
           display:block
        }
        </style>
	</head>
	<body>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="../../index.html" class="logo"><strong>Ursinus CS 477: Artificial Intelligence And Machine Learning, Fall 2023</strong></a>
								</header>
<!-- End Header !-->

							<!-- Content -->
								<section>
									<header class="main">
                                        <h2>Homework 6: Build Your Own Multilayer Perceptron (BYOMLP) (45 Points)</h2>
										<h3>Chris Tralie</h3>
									</header>
									
									<h3>
										Table of Contents
										<ul>
											<li><a href = "#objectives">Learning Objectives</a></li>
											<li>
												<a href = "#programming">Programming Tasks</a>
												<ul>
													<li>
														<a href = "#forward">Forward pass (10 Points)</a>
													</li>
													<li>
														<a href = "#backprop">Backpropagation (15 Points)</a>
													</li>
													<li>
														<a href = "#digits">Digits Classification (10 Points)</a>
													</li>
													<li>
														<a href = "#autoencoder">Digits Autoencoder (10 Points)</a>
														<ul>
															<li>
																<a href = "#architecture">Architecture</a>
															</li>
															<li>
																<a href = "#training">Training</a>
															</li>
															<li>
																<a href = "#latenttraverse">Latent Traversal (For Fun)</a>
															</li>
														</ul>
													</li>
												</ul>

											</li>
										</ul>

									</h3>

									<div id="page-content">

										<h2><a name = "logistics">Logistics / Getting Started</a></h2>

										<p>
											In this assignment, you will implement your own multilayer perceptron (MLP) neural network solver from scratch in python using only numpy and matplotlib.  No special libraries like pytorch are required!  My aim is to show you how simple the fundamental math ideas really are under the hood, and how most of modern neural nets is just software engineering.  If you're still not convinced, read <a href = "https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b">this article</a> by Andrej Karpathy.  
										</p>

										<p>
											You will apply this to both a supervised task: classifying digits, as well as an unsupervised task: learning a low dimensional representation of digits from their high dimensional pixel-based representations.  We will be doing something similar to <a href = "https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b">Karpathy's "micrograd" setup</a>, although specializing it to MLPs with matrix multiplication will make it fast enough to do what we need it to do (micrograd is too slow for the applications in this assignment).
										</p>

										<p>
											<a href = "https://github.com/ursinus-cs477-f2023/HW6_BYOMLP/archive/refs/heads/main.zip">Click here</a> to download the starter code for this assignment.  Most of your edits will occur in <code>mlp.py</code>.  When you are finished, turn in your <code>mlp.py</code> file, as well as your notebook <code>Classification.ipynb</code> and <code>Autoencoder.ipynb</code>
										</p>
	

                                        <p>
                                            <h2><a name = "objectives">Learning Objectives</a></h2>
                                            <ul>
												<li>
													Implement a fast backpropagation algorithm for multilayer perceptrons using numpy operations
												</li>
												<li>
													Implement stochastic gradient descent and batch gradient descent
												</li>
												<li>
													Explore different MLP architectures for supervised learning
												</li>
												<li>
													Implement an MLP-based autoencoder to perform unsupervised dimension reduction
												</li>
                                            </ul>
										</p>

										
										
									<h2><a name = "programming">Programming Tasks</a></h2>

									

									<h3>
										<a name = "forward">Forward pass (10 Points)</a>
									</h3>
									<p>
										Before we do anything else, we need to get our data structures and forward pass locked down.  In particular, you will setup code for a forward pass in the <code>MLP</code> class in <code>mlp.py</code>.
									</p>

									<h4>Your Task</h4>
									<p>
										Have a look at the <a href = "../../ClassExercises/Week10_Backprop/index.html#forwardalg">pseudocode for the forward pass algorithm</a> and fill in the methods <code>__init__</code>, <code>add_layer</code>, and <code>forward</code> in <code>mlp.py</code>.  
									</p>
									<p>
										When you add a layer, you should store as instance variables a weights matrix and a bias matrix of the appropriate shape, as well as the function handles for the nonlinear function and its derivative <code>f</code> and <code>fderiv</code>, respectively, at this layer.  <b>The weights should be a 2D array, and the biases should be a 1D array</b><SUP><a href = "#bias1d">*</a></SUP>, and you should randomly initialize them using <code><a href = "https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html">np.random.randn</a></code>.  <b>Be sure to multiply the initial weights by 0.1 to make sure their standard deviation is 0.1</b> (smaller standard deviation weights tend to perform better).  There is also an optional parameter called "name" that you can use to assign a string name to this layer.  This will help us with the <a href = "#disctest">disc test</a> and <a href = "#autoencoder">autoencoder</a> task later.
									</p>
									<p>
										When you do a forward pass, it will help if you store the <code>a</code>'s and <code>h</code>'s (as defined in  <a href = "../../ClassExercises/Week10_Backprop/index.html#forwardalg">the notes</a>) at each layer as instance variables, as you can look them up later when you do backpropagation.  You should also take into consideration the optional <code>start</code> and <code>end</code> parameters, which you can use to start an input in the middle of the network and end early.
									</p>
									<p>
										<a name = "bias1d">*</a> It's true that in the notes I had the bias as a column vector, which is technically a 2D array, but it will make things easier if we keep the bias as a 1D array for now
									</p>

									<h4>Tips</h4>
									<p>
										You may want to look back at the beginning of the <a href = "../../../Modules/Backprop/Video1">backprop module</a> to see an example of how to represent and store weights/biases/functions and then apply them in a forward loop, though we're adding some embellishments here, and we're encapsulating the layers in a class.
									</p>

									<h4>Testing</h4>

									<p>
										As an example, suppose you had the following code:
									</p>


									<script type="syntaxhighlighter" class="brush: python"><![CDATA[
										model = MLP(10, logistic_loss_deriv)
										model.add_layer(20, leaky_relu, leaky_relu_deriv)
										model.add_layer(5, leaky_relu, leaky_relu_deriv, "special_start")
										model.add_layer(8, leaky_relu, leaky_relu_deriv)
										model.add_layer(7, leaky_relu, leaky_relu_deriv, "special_end")
										model.add_layer(1, leaky_relu, leaky_relu_deriv)
										x = np.random.randn(10)
										y = model.forward(x)
										print(y.shape)
										# Show how to start/end in the middle of the network
										x = np.random.randn(20)
										y = model.forward(x, start="special_start", end="special_end")
										print(y.shape)
									</script> 

									<p>
										The first pass should output an array with a single element, since it goes from 10, to 20, to 5, to 8, to 7, to 1.  The second pass takes in an array of 20 elements (the input to "special_start") and should output an array of 7 elements (the output of "special_end").
									</p>

									<HR>
									<h3>
										<a name = "backprop">Backpropagation (15 Points)</a>
									</h3>
									<p>
										Now we're ready to finish the API for our MLPs by implementing backpropagation to train them.  
									</p>

									<h4>Your Task</h4>
									<p>
										First, fill in the method <code>backward</code> to do a forward pass, followed by backpropagation, with respect to a particular input/output pair <code>x</code> and <code>y</code>.  During backpropagation, compute and accumulate the gradients of all of the weights and biases at each layer.  Refer to the <a href = "../../ClassExercises/Week10_Backprop/index.html#backpropalg">pseudocode in the backprop notes</a> for how to do this.  As part of this, you'll want to add instance variables to store the derivatives of all weights and biases, which you should reset to 0 when calling the <code>zero_grad</code> method.
									</p>

									<p>
										Finally, fill in the <code>step</code> method to subtract <code>alpha</code> times the accumulated gradients from the weights/biases.
									</p>



									<h4><a name = "disctest">Testing</a></h4>
									<p>
										To help you test your system, I've provided the notebook <code>DiscTest.ipynb</code> which will learn a network to separate the points on the inside of a disc from the points on the outside of the disc, which <i>is not something that we could do with 2D logistic regression</i>!  Dataset shown below:
									</p>

									<img src = "DiscData.svg">

									<p>
										
										To do the separation, we use a network with the following three layers:
										<ol>
											<li>
												100 neurons with a leaky ReLU
											</li>
											<li>
												2 neurons with a leaky ReLU
											</li>
											<li>
												The final output neuron with a logistic activation, using the logistic loss
											</li>
										</ol>
									</p>
									<p>
										Using our little API, we can define this network with the following code
									</p>
									<script type="syntaxhighlighter" class="brush: python"><![CDATA[
										nn = MLP(2, logistic_est_loss_deriv) # Input is in 2 dimensions, and we want to use logistic loss
										
										nn.add_layer(100,  leaky_relu, leaky_relu_deriv, name="layer1") # First layer outputs 100 dimensions with a leaky ReLU
										
										nn.add_layer(2, leaky_relu, leaky_relu_deriv, name="layer2") # Second layer outputs 2 dimensions with a leaky ReLU.  
										# Data should be linearly separatable after this layer

										nn.add_layer(1, logistic, None, name="lastlayer") # Last layer is the logistic function.  Its derivative is handled separately
									</script>  

									<p>
										Then, we can perform <a name = "stochastic"><b>stochastic gradient descent</b></a> on each epoch; that is, we shuffle all of the examples and send them through one by one, updating the weights each time.  This is all in the notebook already and you can just run it.  If it works properly, you should see an animation like this, where the left plot shows the 2 coordinates of the output of <code>layer2</code>, and the right plot shows the loss over time.  As you can see, after a few iterations, the orange and blue points become linearly separable after the output of <code>layer2</code>.
									</p>

									<img src = "DiscResult.gif" width="80%">

									<HR>
									<h3>
										<a name = "digits">Digits Classification (10 Points)</a>
									</h3>

									<p>
										We're now ready to apply our MLPs to our first real application: digit classification!  
									</p>
									<p>
										We'll use a loss function which is a generalization of the <a href = "../../ClassExercises/Week10_LogisticRegression/index.html#logisticloss">logistic loss</a> to multivariate output.  Given the output <b>y<SUB>est</SUB></b> of the softmax function and the ground truth 1-hot vectors <b>y</b>, we can define the <b>multivariate cross-entropy logistic loss</b> as 
									</p>

									<div style="width:100px;">
									<h3>
										\[ L(y, y_{\text{est}}) = -\sum_{i=1}^N  y[i] \log(y_{\text{est}}[i]) \]
									</h3>
									</div>

									<p>
										where in our digits problem <b>N = 10</b>.  We need to take the gradient of this loss with respect to the input to the logistic function, but this is actually incredibly simple and exactly like the single variable logistic loss case.  In particular, the gradient of the <b>i<SUP>th</SUP></b> component to the input of the softmax function is simply
										<b>y<SUB>est</SUB>[i] - y[i]</b>
										<h3>
											<b>y<SUB>est</SUB>[i] - y[i]</b>
										</h3>
										
										This should look pretty familiar! For details, look back to the <a href = "../HW5_LogisticRegression/index.html#logisticbbow">update rules</a> in the last assignment, and refer to my <a href = "../../../Modules/Softmax/Video1">derivation in the softmax module</a>.  To save time, I've already implemented this for you.  The loss function and its derivatives are the methods <code>softmax_est_crossentropy_loss</code> and <code>softmax_est_crossentropy_deriv</code>, respectively, in the <code>losses.py</code> file.
									</p>

									<p>
										<h4>Your Task</h4> Create a Jupyter notebook <code>Classification.ipynb</code> to train a neural network in our little API that classifies digits in the MNIST dataset.  Train a network using <a href = "#stochastic">stochastic gradient descent</a> on the training set for 100 iterations</b>, and report the accuracy on all of the images on both the training set and the test set.  To load train set, use the <code>load_images</code> method in <code>digits.py</code>:
										<script type="syntaxhighlighter" class="brush: python"><![CDATA[
											X, Y = get_digits("Digits")
											XTest, YTest = get_digits("DigitsTest")
										</script>  
										

									</p>
									<p>
										You should compare two networks: the first network should have a single hidden layer with 20 neurons and a softmax output, which you can define like this:

										<script type="syntaxhighlighter" class="brush: python"><![CDATA[
											nn = NeuralNet(x_train.shape[1], softmax_est_crossentropy_deriv)
											nn.add_layer(20, leaky_relu, leaky_relu_deriv)
											nn.add_layer(10, softmax, None)
										</script>  
										
										The second network should have an additional ReLU layer with 40 neurons at the beginning before the layers with 20 and 10.  <b>Indicate clearly in your notebook which network works better and why you think this is</b>, and if it seems like either network is overfitting at some point.
									</p>
									
								<HR>
									<h3>
										<a name = "autoencoder">Digits Autoencoder (10 Points)</a>
									</h3>

									<p>
										In this task, you will create an autoencoder (encoder/decoder network) to compute a dimension reduced representation of the digits, which serves as a warmup for more complicated examples such as <a href = "https://youtu.be/iuQ_f3W5Ttk?si=IB4nTU87lsboRtC6&t=204">low dimensional representations of face images</a>.
									</p>
									<p>
										Up to this point, the only technique we've seen for unsupervised dimension reduction is <a href = "../../ClassExercises/Week7_PCA/Week7_PCA/UnsupervisedDigits.html">principal component analysis (PCA)</a>, which is a <i>linear dimension reduction technique</i>; in particular, it fits a flat to data in high dimensions.  To help visualize digit dimension reductions, I've created a method in <code>digits.py</code> called <code>plot_digits_dimreduced_examples</code> that shows examples of encodings projecting digits to their dimension reduced representation, as well as some example decodings back up to pixel space.  The following code implements PCA in an API compatible with this:
									</p>

									<script type="syntaxhighlighter" class="brush: python"><![CDATA[
										class PCAModel:
											"""
											A class that performs PCA and is compatible with the plotting
											interface for showing the latent space of digits
											"""
											def __init__(self, X):
												import numpy.linalg as linalg
												mu = np.mean(X, axis=0)
												self.mu = mu
												X = X - mu[None, :]
												A = (X.T).dot(X)
												v, U = linalg.eigh(A)
												self.U = U[:, -2::]
												v[v < 0] = 0
												v = v[::-1]
												print("Variance Explained: {:.2f}%".format(100*np.sum(v[0:2])/np.sum(v)))
											
											def forward(self, x, end=None):
												x = x - self.mu
												u = (self.U.T).dot(x)
												if end == "latent":
													ret = u
												else:
													ret = self.U.dot(u) + self.mu
													ret[ret < 0] = 0
													ret[ret > 1] = 1
												return ret
											
										X, Y = get_digits("Digits")
										model = PCAModel(X)
										plt.figure(figsize=(10, 10))
										plot_digits_dimreduced_examples(X, Y, model)
									</script>  

									<p>
										The two principal components with the highest variance explain 16.8% of the variance in the dataset, and examples of encodings look like this:
									</p>

									<img src = "PCA.png" width="80%">

									<p>
										This is not bad for a linear dimension reduction technique!  We can certainly see the separation between 0 and 1, and the 4's, 7's and 9's are in one cluster (though they're mixed up).  One downside, though, is that every decoded result from the 2D "latent space" is very blurry. To improve this, we'll turn to an <b>neural autoencoder</b>, which is a <i>nonlinear dimension reduction technique</i> that we can create using our MLP API.
									</p>

									<h4>Your Task</h4>
									<p>
										Create a notebook <code>Autoencoder.ipynb</code> in which you create and train an autoencoder for digits.
									</p>

									<h4><a name = "architecture">Architecture</a></h4>
									<p>
										You should use the following architecture
									</p>
									<img src = "AutoencoderArchitecture.svg" width="60%">
									<p>
										It has the following properties:
									</p>
									<ul>
										<li>The input and output are both flattened 784 dimension representations of the pixels</li>
										<li>
											Name the 2D latent layer <code>"latent"</code> and the layer right after that <code>"up128"</code>.  This will help with plotting and debugging
										</li>
										<li>
											Every layer, except for the latent layer and the last layer, uses leaky ReLUs.  The 2D latent and last layer use logistic functions.
											<p>
												The rationale for this is that having a logistic at the latent layer squashes the dimension reduced representation to the box [0, 1] x [0, 1], which forces it to fill out the box.  Having a logistic as the last layer gives the network a hint that the grayscale values in the output should be between 0 and 1.
											</p>
										</li>
									</ul>

									<h4><a name = "training">Training</a></h4>
									<p>
										To train the network, use <b>squared loss</b> (which is provided in <code>losses.py</code>) and <b>batch gradient descent</b> with a <b>batch size of 16</b>.  This means that every epoch, you should shuffle the data and accumulate the gradient over every run of 16 examples, taking a gradient descent step and resetting the gradients once these gradients have been accumulated.  Go for at least 3 epochs (this may take a few minutes).  Use an initial <b>learning rate of <code>1e-4</code></b>, and shrink this learning factor by 2x at the end of each epoch.
									</p>

									<p>
										To see if this is working properly, use the <code>plot_digits_dimreduced_examples</code> method.  Below is an animation of the training of a properly working example.  You'll notice that as the learning rate decreases, it settles down into a local min.  <b>Your results may be different due to random initialization of the weights!</b>
									</p>

									<img src = "autoencoder_train.gif" width="80%">
									<p>
										And below is the final frame.  Notice how, compared to PCA, the digits are separated out better, and the encodings are a bit sharper.  There is still a lot of confusion between 4/7/9, but we did much better separating out 2 and 6 from the rest, and the variance in the 1 and 0 classes are much more visible.
									</p>
									<img src = "autoencoder_result.png" width="80%">
									<p>

									</p>

									<h4><a name = "latenttraverse">Latent Traversal (For Fun)</a></h4>
									<p>
										This autoencoder gives us a nice way to interpolate between examples.  To get started, note that we can input a 2D vector and put it through the decoder part by starting at <code>"up128"</code>
									</p>

									<script type="syntaxhighlighter" class="brush: python"><![CDATA[
										u = [0.1, 0.1]
										I = model.forward(u, start="up128")
										I = np.reshape(I, (28, 28))
										plt.imshow(I, cmap='gray', vmin=0, vmax=1)
										plt.title("u = {}".format(u))
									</script>  

									<p>
										In my trained network above, this gives the following:
									</p>
									<img src = "LatentExample.png" width="25%">
									<p>
										Which makes sense, because the lower left is in the 1's range of the image.  We can go further and make an animation of traversing the latent space.  For instance, let's suppose I wanted to go around a circle
									</p>

									<script type="syntaxhighlighter" class="brush: python"><![CDATA[
										t = np.linspace(0, 2*np.pi, 300)
										xs = 0.5 + 0.4*np.cos(t)
										ys = 0.5 + 0.4*np.sin(t)
										
										plt.figure(figsize=(10, 10))
										for i, (x, y) in enumerate(zip(xs, ys)):
											u = [x, y]
											I = model.forward(u, start="up128")
											I = np.reshape(I, (28, 28))
											plt.clf()
											plt.subplot2grid((5, 5), (0, 0), colspan=1, rowspan=1)
											plt.imshow(I, cmap='gray', vmin=0, vmax=1)
											plt.axis("off")
											plt.subplot2grid((5, 5), (1, 0), colspan=5, rowspan=4)
											scatter_digits(model, X, Y, n_scatter=1000)
											plt.scatter(x, y, c='k', s=100, zorder=100)
											plt.savefig("LatentInterp{}.png".format(i))
									</script>  

									<p>
										Then I'd get the following animation on my network:
									</p>
									<img src = "latentTraverse.gif">



									<p>
										This really gives an idea of how everything is connected in the latenet space!  This all gets even more exciting when we move on from these low resolution digits to, for instance, <a href = "https://youtu.be/iuQ_f3W5Ttk?si=tTvfLi2uPI1vFO_r&t=292">face images</a>!
									</p>
									
                                </div>
						</div>
					</div>

					<!--LaTeX in Javascript!-->
					<script src="../../../../jsMath/easy/load.js"></script>
					<!--Syntax highlighting in Javascript!-->
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shCore.js"></script>
					<script type="text/javascript" src="../../../syntaxhighlighter/scripts/shBrushJScript.js"></script>
                    <script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushCpp.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushXml.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushMatlabSimple.js"></script>
					<script type="text/javascript" src="../../../../syntaxhighlighter/scripts/shBrushPython.js"></script>
					<link type="text/css" rel="stylesheet" href="../../../../syntaxhighlighter/styles/shCoreDefault.css"/>
					<script type="text/javascript">SyntaxHighlighter.all();</script>

<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
                                        <li>
											<span class="opener">General</span>
											<ul>
												<li><a href = "../../index.html#overview">Overview</a></li>
												<li><a href = "../../index.html#logistics">Technology Logistics</a></li>
												<li><a href = "../../index.html#deliverables">Deliverables</a></li>
												<li><a href = "../../index.html#debugging">Debugging Principles</a></li>
												<li><a href = "../../index.html#schedule">Schedule</a></li>
												<li><a href = "../../index.html#grading">Grading / Deadlines Policy</a></li>
												<li><a href = "../../index.html#environment">Classroom Environment</a></li>
												<li><a href = "../../index.html#collaboration">Collaboration Policy</a></li>
												<li><a href = "../../index.html#other">Other Resources / Policies</a></li>
											</ul> 
										</li>
										<li><a href = "../../Software/index.html">Software</a></li>
										<li><a href = "../../index.html#schedule">Schedule</a></li>
                                        <li>
											<span class="opener">Assignments</span>
											<ul>
												<li>
													<a href = "../../../Modules/Module1/Video1">HW0: Python Self Study Module</a>
												</li>
												<li>
													<a href = "../../Assignments/HW1_WelcomeToCS477">HW1: Welcome To CS 477</a>
												</li>
												
												<li>
													<a href = "../../Assignments/HW2_RushHour">HW2: The Rush Hour Problem</a>
												</li>
												<li>
													<a href = "../../Assignments/HW3_Markov">HW3: Markov Chains for Text Processing</a>
												</li>
												<li>
													<a href = "../../Assignments/HW4_FundamentalFreq">HW4: Fundamental Frequency Tracking And Pitch-Based Audio Effects</a>
													<ul>
														<li>
															<a href = "../../Assignments/HW4_FundamentalFreq/statements.html">Musical statements</a>
														</li>
													</ul>
												</li>
												<li>
													<a href = "../../Assignments/HW5_LogisticRegression">HW5: Logistic Regression on Movie Reviews</a>
												</li>
												<li>
													<a href = "../../Assignments/HW6_BYOMLP">HW6: Build Your Own Multilayer Perceptron (BYOMLP)</a>
												</li>
												<!--
												<li>
													<a href = "../../Assignments/HW7_DeepLearning">HW7: (Deep) Neural Networks on Images</a>
												</li>
												!-->
											</ul>
										</li>
                                        <li>
											<span class="opener">Class Exercises / Notes</span>
											<ul>
												<li>
													<a href = "../../ClassExercises/Week1_Bandit/index.html">Week 1: Introduction To Reinforcement Learning</a>
													<ul>
														<li>
															<a href = "../../ClassExercises/Week1_Bandit/jsbandit/index.html">The Multi-Armed Bandit Game</a>
														</li>
													</ul>
												</li>
												<li>
													<a href = "../../ClassExercises/Week1_Adventure">Week 1: Choose Your Own Adventure</a>
													<ul>
														<li><a href = "../../ClassExercises/Week1_Adventure/index.html#student">Student Adventures</a></li>
													</ul>
												</li>
												<li>
													<a href = "../../Materials/MazeExplorer">Week 2: Maze Searching Game</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week2_BasicSearch">Week 2: Blind Maze Searching</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week2_8Puzzle">Week 2: 8 Puzzle</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week3_PrioritySearch">Week 3: Uniform Cost, Greedy Best-First, and A* Search</a>
												</li>
												<li>
													<a href = "https://ursinus.instructure.com/courses/16260/assignments/186957">Week 3: An Admissible But Not Consistent Heuristic</a>
												</li>
												<li>
													<a href = "../../../Modules/Module2/Video1">Week 4: Probability Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week4_Markov">Week 4: Markov Chains of Characters</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week4_MarkovText">Week 4: Markov Chains for Document Representations</a>
												</li>
												<li>
													<a href = "https://ursinus.instructure.com/courses/16260/quizzes/24127">Week 4: Bayes Rule Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_NaiveBayes">Week 5: Bayes Rule And Naive Bayes Classifiers</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_BagOfWords">Week 5: Bag of Words Naive Bayes Exercise</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week6_HMM">Week 5/6: Hidden Markov Models / Bayes Filtering / Viterbi Notes</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_RobotLocalization">Week 5/6: Robot Localization</a>
												</li>
												<li>
													<a href = "https://ursinus-cs477-f2023.github.io/Modules/HMM/Video1">Week 6: HMM Module</a>
												</li>
												<li>
													<a href = "https://github.com/ursinus-cs477-f2023/Week6_MDP">Week 6: Markov Decision Processes And Pong AI</a>
												</li>
												<li>
													<a href = "../../../Modules/VectorModule/Video1">Week 7: Euclidean Vectors / Data Vectorization Module</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week7_DigitsNN/index.html">Week 7: K-Nearest Neighbors And Digits Classification</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week5_KMeans">Week 7: KMeans Clustering And Visual Bag of Words</a>
												</li>
												<li>
													<a href = "../../../Modules/MatrixModule/Video1">Week 7: Matrix Module</a>
												</li>
												<li>
													<a href = "ClassExercises/Week7_PCA/Week7_PCA/UnsupervisedDigits.html">Week 7: PCA on MNIST Digits</a>
												</li>
												<li>
													<a href = "../../ClassExercises/Week10_LogisticRegression/index.html">Week 8: Logistic Regression And Gradient Descent</a>
												</li>
												<li>
													<a href = "../../../Modules/LogisticRegression/Video1">Week 8: Neural Networks Module 1</a>
												</li>
												<li>
													<a href = "../../../Modules/Softmax/Video1">Week 9: Softmax Module</a>
												</li>
												<li><a href = "../../../Modules/NeuralNets/Video0">Week 9/10: Multi-Class Logistic Regression And Feedforward Neural Nets Module</a></li>
												<li>
													<a href = "../../ClassExercises/Week10_Backprop/index.html">Week 10: Backpropagation on Multilayer Perceptrons</a>
												</li>
												<li>
													<a href = "../../../Modules/Backprop/Video1">Week 10: Backpropagation Module</a>
												</li>
												
												
											</ul>
										</li>
										<li><a href = "../../Ethics/index.html">Ethics Reading / Discussions</a></li>
										<li><a href = "../../FinalProject/index.html">Final Ethics Project</a></li>
									</ul>
								</nav>


							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; <a href = "http://www.ctralie.com">Christopher J. Tralie</a>. All rights reserved.  Contact chris.tralie@gmail.com. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

			</div>
			
            <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
            <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- End Sidebar !-->

<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/skel.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="../../assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="../../assets/js/main.js"></script>
<!-- End Scripts -->
